                      :-) GROMACS - gmx mdrun, 2019.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov      Paul Bauer     Herman J.C. Berendsen
    Par Bjelkmar      Christian Blau   Viacheslav Bolnykh     Kevin Boyd    
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra       Alan Gray     
  Gerrit Groenhof     Anca Hamuraru    Vincent Hindriksen  M. Eric Irrgang  
  Aleksei Iupinov   Christoph Junghans     Joe Jordan     Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul    Viveca Lindahl    Magnus Lundborg     Erik Marklund   
    Pascal Merz     Pieter Meulenhoff    Teemu Murtola       Szilard Pall   
    Sander Pronk      Roland Schulz      Michael Shirts    Alexey Shvetsov  
   Alfons Sijbers     Peter Tieleman      Jon Vincent      Teemu Virolainen 
 Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2018, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2019.3
Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   394759
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  


Running on 1 node with total 36 cores, 36 logical cores
Hardware detected:
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) Gold 6240 CPU @ 2.60GHz
    Family: 6   Model: 85   Stepping: 7
    Features: aes apic avx avx2 avx512f avx512cd avx512bw avx512vl clfsh cmov cx8 cx16 f16c fma hle htt intel lahf mmx msr nonstop_tsc pcid pclmuldq pdcm pdpe1gb popcnt pse rdrnd rdtscp rtm sse2 sse3 sse4.1 sse4.2 ssse3 tdt x2apic
    Number of AVX-512 FMA units: 2
  Hardware topology: Only logical processor count


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
M. J. Abraham, T. Murtola, R. Schulz, S. Páll, J. C. Smith, B. Hess, E.
Lindahl
GROMACS: High performance molecular simulations through multi-level
parallelism from laptops to supercomputers
SoftwareX 1 (2015) pp. 19-25
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Páll, M. J. Abraham, C. Kutzner, B. Hess, E. Lindahl
Tackling Exascale Software Challenges in Molecular Dynamics Simulations with
GROMACS
In S. Markidis & E. Laure (Eds.), Solving Software Challenges for Exascale 8759 (2015) pp. 3-27
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Pronk, S. Páll, R. Schulz, P. Larsson, P. Bjelkmar, R. Apostolov, M. R.
Shirts, J. C. Smith, P. M. Kasson, D. van der Spoel, B. Hess, and E. Lindahl
GROMACS 4.5: a high-throughput and highly parallel open source molecular
simulation toolkit
Bioinformatics 29 (2013) pp. 845-54
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess and C. Kutzner and D. van der Spoel and E. Lindahl
GROMACS 4: Algorithms for highly efficient, load-balanced, and scalable
molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 435-447
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
D. van der Spoel, E. Lindahl, B. Hess, G. Groenhof, A. E. Mark and H. J. C.
Berendsen
GROMACS: Fast, Flexible and Free
J. Comp. Chem. 26 (2005) pp. 1701-1719
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
E. Lindahl and B. Hess and D. van der Spoel
GROMACS 3.0: A package for molecular simulation and trajectory analysis
J. Mol. Mod. 7 (2001) pp. 306-317
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
H. J. C. Berendsen, D. van der Spoel and R. van Drunen
GROMACS: A message-passing parallel molecular dynamics implementation
Comp. Phys. Comm. 91 (1995) pp. 43-56
-------- -------- --- Thank You --- -------- --------


++++ PLEASE CITE THE DOI FOR THIS VERSION OF GROMACS ++++
https://doi.org/10.5281/zenodo.3243833
-------- -------- --- Thank You --- -------- --------

Non-default thread affinity set, disabling internal thread affinity
Input Parameters:
   integrator                     = md
   tinit                          = 0
   dt                             = 0.002
   nsteps                         = 1000000000000
   init-step                      = 0
   simulation-part                = 1
   comm-mode                      = Linear
   nstcomm                        = 100
   bd-fric                        = 0
   ld-seed                        = 1974013184
   emtol                          = 10
   emstep                         = 0.01
   niter                          = 20
   fcstep                         = 0
   nstcgsteep                     = 1000
   nbfgscorr                      = 10
   rtpi                           = 0.05
   nstxout                        = 50000
   nstvout                        = 0
   nstfout                        = 0
   nstlog                         = 50000
   nstcalcenergy                  = 100
   nstenergy                      = 50000
   nstxout-compressed             = 50000
   compressed-x-precision         = 1000
   cutoff-scheme                  = Verlet
   nstlist                        = 10
   ns-type                        = Grid
   pbc                            = xyz
   periodic-molecules             = false
   verlet-buffer-tolerance        = 0.005
   rlist                          = 1
   coulombtype                    = PME
   coulomb-modifier               = Potential-shift
   rcoulomb-switch                = 0
   rcoulomb                       = 1
   epsilon-r                      = 1
   epsilon-rf                     = inf
   vdw-type                       = Cut-off
   vdw-modifier                   = Potential-shift
   rvdw-switch                    = 0
   rvdw                           = 1
   DispCorr                       = EnerPres
   table-extension                = 1
   fourierspacing                 = 0.16
   fourier-nx                     = 72
   fourier-ny                     = 72
   fourier-nz                     = 72
   pme-order                      = 4
   ewald-rtol                     = 1e-05
   ewald-rtol-lj                  = 0.001
   lj-pme-comb-rule               = Geometric
   ewald-geometry                 = 0
   epsilon-surface                = 0
   tcoupl                         = V-rescale
   nsttcouple                     = 10
   nh-chain-length                = 0
   print-nose-hoover-chain-variables = false
   pcoupl                         = Parrinello-Rahman
   pcoupltype                     = Isotropic
   nstpcouple                     = 10
   tau-p                          = 2
   compressibility (3x3):
      compressibility[    0]={ 4.50000e-05,  0.00000e+00,  0.00000e+00}
      compressibility[    1]={ 0.00000e+00,  4.50000e-05,  0.00000e+00}
      compressibility[    2]={ 0.00000e+00,  0.00000e+00,  4.50000e-05}
   ref-p (3x3):
      ref-p[    0]={ 1.00000e+00,  0.00000e+00,  0.00000e+00}
      ref-p[    1]={ 0.00000e+00,  1.00000e+00,  0.00000e+00}
      ref-p[    2]={ 0.00000e+00,  0.00000e+00,  1.00000e+00}
   refcoord-scaling               = No
   posres-com (3):
      posres-com[0]= 0.00000e+00
      posres-com[1]= 0.00000e+00
      posres-com[2]= 0.00000e+00
   posres-comB (3):
      posres-comB[0]= 0.00000e+00
      posres-comB[1]= 0.00000e+00
      posres-comB[2]= 0.00000e+00
   QMMM                           = false
   QMconstraints                  = 0
   QMMMscheme                     = 0
   MMChargeScaleFactor            = 1
qm-opts:
   ngQM                           = 0
   constraint-algorithm           = Lincs
   continuation                   = true
   Shake-SOR                      = false
   shake-tol                      = 0.0001
   lincs-order                    = 4
   lincs-iter                     = 1
   lincs-warnangle                = 30
   nwall                          = 0
   wall-type                      = 9-3
   wall-r-linpot                  = -1
   wall-atomtype[0]               = -1
   wall-atomtype[1]               = -1
   wall-density[0]                = 0
   wall-density[1]                = 0
   wall-ewald-zfac                = 3
   pull                           = false
   awh                            = false
   rotation                       = false
   interactiveMD                  = false
   disre                          = No
   disre-weighting                = Conservative
   disre-mixed                    = false
   dr-fc                          = 1000
   dr-tau                         = 0
   nstdisreout                    = 100
   orire-fc                       = 0
   orire-tau                      = 0
   nstorireout                    = 100
   free-energy                    = no
   cos-acceleration               = 0
   deform (3x3):
      deform[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   simulated-tempering            = false
   swapcoords                     = no
   userint1                       = 0
   userint2                       = 0
   userint3                       = 0
   userint4                       = 0
   userreal1                      = 0
   userreal2                      = 0
   userreal3                      = 0
   userreal4                      = 0
   applied-forces:
     electric-field:
       x:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
       y:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
       z:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
grpopts:
   nrdf:     13160.8      222576
   ref-t:         300         300
   tau-t:         0.1         0.1
annealing:          No          No
annealing-npoints:           0           0
   acc:	           0           0           0
   nfreeze:           N           N           N
   energygrp-flags[  0]: 0

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.454 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.454 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
G. Bussi, D. Donadio and M. Parrinello
Canonical sampling through velocity rescaling
J. Chem. Phys. 126 (2007) pp. 014101
-------- -------- --- Thank You --- -------- --------

There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 75 min 4289 max 4626

Started mdrun on rank 0 Sun Jan 12 22:47:52 2020

           Step           Time
              0        0.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Ryckaert-Bell.          LJ-14     Coulomb-14
    1.31131e+04    7.43495e+02    6.17820e+03    9.77778e+03    5.15413e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    3.28241e+05   -1.58634e+04   -2.24237e+06    1.06330e+04   -1.83800e+06
    Kinetic En.   Total Energy  Conserved En.    Temperature Pres. DC (bar)
    2.93000e+05   -1.54500e+06   -1.54493e+06    2.98976e+02   -2.25711e+02
 Pressure (bar)   Constr. rmsd
    1.60558e+02    2.70869e-05


DD  step 49 load imb.: force  8.4%  pme mesh/force 6.499
step  200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76943.9 M-cycles
step  300: timed with pme grid 60 60 60, coulomb cutoff 1.097: 74549.8 M-cycles
step  400: timed with pme grid 52 52 52, coulomb cutoff 1.266: 69475.3 M-cycles
step  500: timed with pme grid 48 48 48, coulomb cutoff 1.371: 75426.3 M-cycles
step  600: timed with pme grid 44 44 44, coulomb cutoff 1.496: 70369.5 M-cycles
step  600: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step  700: timed with pme grid 44 44 44, coulomb cutoff 1.496: 70898.9 M-cycles
step  800: timed with pme grid 48 48 48, coulomb cutoff 1.371: 74619.2 M-cycles
step  900: timed with pme grid 52 52 52, coulomb cutoff 1.266: 76903.7 M-cycles
step 1000: timed with pme grid 56 56 56, coulomb cutoff 1.176: 72415.7 M-cycles
step 1100: timed with pme grid 60 60 60, coulomb cutoff 1.097: 75666.9 M-cycles
step 1200: timed with pme grid 64 64 64, coulomb cutoff 1.029: 69363.8 M-cycles
Writing checkpoint, step 1200 at Sun Jan 12 23:03:38 2020


step 1300: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70603.2 M-cycles
step 1400: timed with pme grid 44 44 44, coulomb cutoff 1.496: 71869.4 M-cycles
step 1500: timed with pme grid 48 48 48, coulomb cutoff 1.371: 70901.5 M-cycles
step 1600: timed with pme grid 52 52 52, coulomb cutoff 1.266: 75311.6 M-cycles
step 1700: timed with pme grid 56 56 56, coulomb cutoff 1.176: 69372.0 M-cycles
step 1800: timed with pme grid 60 60 60, coulomb cutoff 1.097: 74317.0 M-cycles
step 1900: timed with pme grid 64 64 64, coulomb cutoff 1.029: 75613.9 M-cycles
step 2000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71775.7 M-cycles
step 2100: timed with pme grid 44 44 44, coulomb cutoff 1.496: 71810.6 M-cycles
step 2200: timed with pme grid 48 48 48, coulomb cutoff 1.371: 70568.2 M-cycles
step 2300: timed with pme grid 52 52 52, coulomb cutoff 1.266: 76071.2 M-cycles
Writing checkpoint, step 2350 at Sun Jan 12 23:18:19 2020


step 2400: timed with pme grid 56 56 56, coulomb cutoff 1.176: 74243.9 M-cycles
step 2500: timed with pme grid 60 60 60, coulomb cutoff 1.097: 71946.7 M-cycles
step 2600: timed with pme grid 64 64 64, coulomb cutoff 1.029: 70713.2 M-cycles
step 2700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72090.1 M-cycles
step 2800: timed with pme grid 44 44 44, coulomb cutoff 1.496: 73036.8 M-cycles
step 2900: timed with pme grid 48 48 48, coulomb cutoff 1.371: 71808.8 M-cycles
step 3000: timed with pme grid 52 52 52, coulomb cutoff 1.266: 78947.9 M-cycles
step 3100: timed with pme grid 56 56 56, coulomb cutoff 1.176: 72531.1 M-cycles
step 3200: timed with pme grid 60 60 60, coulomb cutoff 1.097: 68274.7 M-cycles
step 3300: timed with pme grid 64 64 64, coulomb cutoff 1.029: 74340.8 M-cycles
step 3400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71690.1 M-cycles
step 3500: timed with pme grid 44 44 44, coulomb cutoff 1.496: 70439.2 M-cycles
Writing checkpoint, step 3500 at Sun Jan 12 23:33:12 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   377676
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.453 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.453 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 67 min 4290 max 4586

Started mdrun on rank 0 Sun Jan 12 23:50:25 2020


DD  step 3549 load imb.: force  6.0%  pme mesh/force 6.942
step 3700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73078.8 M-cycles
step 3800: timed with pme grid 60 60 60, coulomb cutoff 1.097: 76004.1 M-cycles
step 3900: timed with pme grid 52 52 52, coulomb cutoff 1.266: 73763.1 M-cycles
step 4000: timed with pme grid 48 48 48, coulomb cutoff 1.372: 75023.7 M-cycles
step 4100: timed with pme grid 44 44 44, coulomb cutoff 1.496: 72166.1 M-cycles
step 4100: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 4200: timed with pme grid 44 44 44, coulomb cutoff 1.496: 75198.5 M-cycles
step 4300: timed with pme grid 48 48 48, coulomb cutoff 1.372: 72129.2 M-cycles
step 4400: timed with pme grid 52 52 52, coulomb cutoff 1.266: 76468.6 M-cycles
step 4500: timed with pme grid 56 56 56, coulomb cutoff 1.176: 76771.2 M-cycles
step 4600: timed with pme grid 60 60 60, coulomb cutoff 1.097: 76239.8 M-cycles
step 4700: timed with pme grid 64 64 64, coulomb cutoff 1.029: 68403.5 M-cycles
Writing checkpoint, step 4700 at Mon Jan 13 00:06:10 2020


step 4800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74851.8 M-cycles
step 4900: timed with pme grid 44 44 44, coulomb cutoff 1.496: 71816.9 M-cycles
step 5000: timed with pme grid 48 48 48, coulomb cutoff 1.372: 70067.1 M-cycles
step 5100: timed with pme grid 52 52 52, coulomb cutoff 1.266: 75063.2 M-cycles
step 5200: timed with pme grid 56 56 56, coulomb cutoff 1.176: 67746.1 M-cycles
step 5300: timed with pme grid 60 60 60, coulomb cutoff 1.097: 74858.8 M-cycles
step 5400: timed with pme grid 64 64 64, coulomb cutoff 1.029: 73627.0 M-cycles
step 5500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70956.0 M-cycles
step 5600: timed with pme grid 44 44 44, coulomb cutoff 1.496: 72184.1 M-cycles
step 5700: timed with pme grid 48 48 48, coulomb cutoff 1.372: 69832.0 M-cycles
step 5800: timed with pme grid 52 52 52, coulomb cutoff 1.266: 76203.2 M-cycles
Writing checkpoint, step 5850 at Mon Jan 13 00:20:44 2020


step 5900: timed with pme grid 56 56 56, coulomb cutoff 1.176: 80353.0 M-cycles
step 6000: timed with pme grid 60 60 60, coulomb cutoff 1.097: 71679.5 M-cycles
step 6100: timed with pme grid 64 64 64, coulomb cutoff 1.029: 69680.1 M-cycles
step 6200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72512.0 M-cycles
step 6300: timed with pme grid 44 44 44, coulomb cutoff 1.496: 70126.0 M-cycles
step 6400: timed with pme grid 48 48 48, coulomb cutoff 1.372: 67307.0 M-cycles
step 6500: timed with pme grid 52 52 52, coulomb cutoff 1.266: 71516.5 M-cycles
step 6600: timed with pme grid 56 56 56, coulomb cutoff 1.176: 73730.9 M-cycles
step 6700: timed with pme grid 60 60 60, coulomb cutoff 1.097: 68960.4 M-cycles
step 6800: timed with pme grid 64 64 64, coulomb cutoff 1.029: 70300.4 M-cycles
step 6900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 68042.5 M-cycles
step 7000: timed with pme grid 44 44 44, coulomb cutoff 1.496: 66444.8 M-cycles
Writing checkpoint, step 7050 at Mon Jan 13 00:35:42 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   441177
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.460 nm, LJ-14, atoms 321 1323
  multi-body bonded interactions: 0.460 nm, Ryckaert-Bell., atoms 321 1323
Minimum cell size due to bonded interactions: 0.506 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.512 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 65 min 4284 max 4551

Started mdrun on rank 0 Mon Jan 13 00:54:56 2020


DD  step 7099 load imb.: force  5.5%  pme mesh/force 3.168
step 7250: timed with pme grid 72 72 72, coulomb cutoff 1.000: 191272.1 M-cycles
step 7350: timed with pme grid 60 60 60, coulomb cutoff 1.098: 111535.2 M-cycles
step 7450: timed with pme grid 52 52 52, coulomb cutoff 1.266: 212975.8 M-cycles
step 7550: timed with pme grid 56 56 56, coulomb cutoff 1.176: 184353.8 M-cycles
Writing checkpoint, step 7550 at Mon Jan 13 01:11:30 2020


step 7650: timed with pme grid 60 60 60, coulomb cutoff 1.098: 145578.0 M-cycles
step 7750: timed with pme grid 64 64 64, coulomb cutoff 1.029: 225974.2 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.098
Writing checkpoint, step 7950 at Mon Jan 13 01:25:47 2020


Writing checkpoint, step 8400 at Mon Jan 13 01:40:46 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   88414
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.455 nm, LJ-14, atoms 3581 4708
  multi-body bonded interactions: 0.455 nm, Ryckaert-Bell., atoms 4708 3581
Minimum cell size due to bonded interactions: 0.501 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.515 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 67 min 4297 max 4589

Started mdrun on rank 0 Mon Jan 13 01:57:47 2020


DD  step 8449 load imb.: force  7.2%  pme mesh/force 5.050
step 8600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 182431.3 M-cycles
step 8700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 211861.9 M-cycles
step 8800: timed with pme grid 64 64 64, coulomb cutoff 1.030: 174691.1 M-cycles
Writing checkpoint, step 8800 at Mon Jan 13 02:13:38 2020


step 8900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 212093.8 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.030
Writing checkpoint, step 9200 at Mon Jan 13 02:28:54 2020


Writing checkpoint, step 9500 at Mon Jan 13 02:43:56 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   187871
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.459 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.459 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.505 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 70 min 4270 max 4534

Started mdrun on rank 0 Mon Jan 13 03:00:48 2020


DD  step 9549 load imb.: force  6.6%  pme mesh/force 6.455
step 9700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 262555.5 M-cycles
step 9800: timed with pme grid 60 60 60, coulomb cutoff 1.097: 233037.5 M-cycles
Writing checkpoint, step 9850 at Mon Jan 13 03:19:02 2020


step 9900: timed with pme grid 52 52 52, coulomb cutoff 1.266: 256486.5 M-cycles
step 10000: timed with pme grid 48 48 48, coulomb cutoff 1.371: 268051.6 M-cycles
step 10100: timed with pme grid 52 52 52, coulomb cutoff 1.266: 252040.8 M-cycles
Writing checkpoint, step 10100 at Mon Jan 13 03:31:55 2020


step 10200: timed with pme grid 56 56 56, coulomb cutoff 1.176: 271169.6 M-cycles
step 10300: timed with pme grid 60 60 60, coulomb cutoff 1.097: 268198.6 M-cycles
step 10400: timed with pme grid 64 64 64, coulomb cutoff 1.029: 264555.8 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.097
Writing checkpoint, step 10400 at Mon Jan 13 03:47:36 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   285098
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.464 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.464 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.510 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.52 nm Y 3.52 nm Z 3.52 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.515 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 63 min 4291 max 4554

Started mdrun on rank 0 Mon Jan 13 04:03:22 2020


DD  step 10449 load imb.: force  6.6%  pme mesh/force 3.979
step 10600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 204554.3 M-cycles
step 10700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 291298.8 M-cycles
step 10800: timed with pme grid 64 64 64, coulomb cutoff 1.030: 238125.7 M-cycles
Writing checkpoint, step 10800 at Mon Jan 13 04:19:58 2020


step 10900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 304961.4 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 11100 at Mon Jan 13 04:36:20 2020


Writing checkpoint, step 11400 at Mon Jan 13 04:49:33 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   430885
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.453 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.453 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 68 min 4303 max 4582

Started mdrun on rank 0 Mon Jan 13 05:03:40 2020


DD  step 11449 load imb.: force  7.7%  pme mesh/force 6.579
step 11600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73149.8 M-cycles
step 11700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 74906.4 M-cycles
step 11800: timed with pme grid 52 52 52, coulomb cutoff 1.267: 73690.4 M-cycles
step 11900: timed with pme grid 48 48 48, coulomb cutoff 1.372: 74383.1 M-cycles
step 12000: timed with pme grid 44 44 44, coulomb cutoff 1.497: 71995.5 M-cycles
step 12000: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 12100: timed with pme grid 44 44 44, coulomb cutoff 1.497: 72089.0 M-cycles
step 12200: timed with pme grid 48 48 48, coulomb cutoff 1.372: 74166.2 M-cycles
step 12300: timed with pme grid 52 52 52, coulomb cutoff 1.267: 75175.8 M-cycles
step 12400: timed with pme grid 56 56 56, coulomb cutoff 1.176: 73029.4 M-cycles
step 12500: timed with pme grid 60 60 60, coulomb cutoff 1.098: 68503.7 M-cycles
step 12600: timed with pme grid 64 64 64, coulomb cutoff 1.029: 76533.5 M-cycles
Writing checkpoint, step 12600 at Mon Jan 13 05:19:23 2020


step 12700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74321.6 M-cycles
step 12800: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74127.5 M-cycles
step 12900: timed with pme grid 48 48 48, coulomb cutoff 1.372: 75851.8 M-cycles
step 13000: timed with pme grid 52 52 52, coulomb cutoff 1.267: 75800.8 M-cycles
step 13100: timed with pme grid 56 56 56, coulomb cutoff 1.176: 75502.8 M-cycles
step 13200: timed with pme grid 60 60 60, coulomb cutoff 1.098: 76126.2 M-cycles
step 13300: timed with pme grid 64 64 64, coulomb cutoff 1.029: 72323.4 M-cycles
step 13400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73633.6 M-cycles
step 13500: timed with pme grid 44 44 44, coulomb cutoff 1.497: 69185.3 M-cycles
step 13600: timed with pme grid 48 48 48, coulomb cutoff 1.372: 70403.2 M-cycles
step 13700: timed with pme grid 52 52 52, coulomb cutoff 1.267: 70846.2 M-cycles
Writing checkpoint, step 13750 at Mon Jan 13 05:34:16 2020


step 13800: timed with pme grid 56 56 56, coulomb cutoff 1.176: 75229.8 M-cycles
step 13900: timed with pme grid 60 60 60, coulomb cutoff 1.098: 77608.5 M-cycles
step 14000: timed with pme grid 64 64 64, coulomb cutoff 1.029: 75212.0 M-cycles
step 14100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73973.8 M-cycles
step 14200: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74022.4 M-cycles
step 14300: timed with pme grid 48 48 48, coulomb cutoff 1.372: 75711.6 M-cycles
step 14400: timed with pme grid 52 52 52, coulomb cutoff 1.267: 76107.4 M-cycles
step 14500: timed with pme grid 56 56 56, coulomb cutoff 1.176: 72357.6 M-cycles
step 14600: timed with pme grid 60 60 60, coulomb cutoff 1.098: 78095.9 M-cycles
step 14700: timed with pme grid 64 64 64, coulomb cutoff 1.029: 75113.6 M-cycles
step 14800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71239.5 M-cycles
Writing checkpoint, step 14850 at Mon Jan 13 05:48:52 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   51724
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.454 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.454 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 70 min 4296 max 4535

Started mdrun on rank 0 Mon Jan 13 06:09:19 2020


DD  step 14899 load imb.: force  4.7%  pme mesh/force 6.325
step 15050: timed with pme grid 72 72 72, coulomb cutoff 1.000: 197181.7 M-cycles
step 15150: timed with pme grid 60 60 60, coulomb cutoff 1.098: 145048.8 M-cycles
step 15250: timed with pme grid 52 52 52, coulomb cutoff 1.267: 163886.7 M-cycles
step 15350: timed with pme grid 56 56 56, coulomb cutoff 1.176: 135473.2 M-cycles
Writing checkpoint, step 15350 at Mon Jan 13 06:25:38 2020


step 15450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 131299.7 M-cycles
step 15550: timed with pme grid 64 64 64, coulomb cutoff 1.029: 207486.1 M-cycles
step 15650: timed with pme grid 56 56 56, coulomb cutoff 1.176: 181120.6 M-cycles
step 15750: timed with pme grid 60 60 60, coulomb cutoff 1.098: 152432.0 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.098
Writing checkpoint, step 15850 at Mon Jan 13 06:41:57 2020


Writing checkpoint, step 16150 at Mon Jan 13 06:56:14 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   347616
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.451 nm, LJ-14, atoms 2029 2976
  multi-body bonded interactions: 0.451 nm, Ryckaert-Bell., atoms 2029 2976
Minimum cell size due to bonded interactions: 0.496 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4305 max 4565

Started mdrun on rank 0 Mon Jan 13 07:08:46 2020


DD  step 16199 load imb.: force  6.3%  pme mesh/force 6.504
step 16350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 80418.5 M-cycles
step 16450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73085.6 M-cycles
step 16550: timed with pme grid 52 52 52, coulomb cutoff 1.267: 69961.8 M-cycles
step 16650: timed with pme grid 48 48 48, coulomb cutoff 1.372: 71082.4 M-cycles
step 16750: timed with pme grid 44 44 44, coulomb cutoff 1.497: 75307.5 M-cycles
step 16750: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 16850: timed with pme grid 44 44 44, coulomb cutoff 1.497: 77844.9 M-cycles
step 16950: timed with pme grid 48 48 48, coulomb cutoff 1.372: 75965.6 M-cycles
step 17050: timed with pme grid 52 52 52, coulomb cutoff 1.267: 72874.4 M-cycles
step 17150: timed with pme grid 56 56 56, coulomb cutoff 1.176: 75085.9 M-cycles
step 17250: timed with pme grid 60 60 60, coulomb cutoff 1.098: 68043.5 M-cycles
step 17350: timed with pme grid 64 64 64, coulomb cutoff 1.029: 72748.8 M-cycles
Writing checkpoint, step 17350 at Mon Jan 13 07:24:29 2020


step 17450: timed with pme grid 44 44 44, coulomb cutoff 1.497: 73610.9 M-cycles
step 17550: timed with pme grid 48 48 48, coulomb cutoff 1.372: 77834.1 M-cycles
step 17650: timed with pme grid 52 52 52, coulomb cutoff 1.267: 67779.9 M-cycles
step 17750: timed with pme grid 56 56 56, coulomb cutoff 1.176: 74609.4 M-cycles
step 17850: timed with pme grid 60 60 60, coulomb cutoff 1.098: 74836.7 M-cycles
step 17950: timed with pme grid 64 64 64, coulomb cutoff 1.029: 73990.6 M-cycles
step 18050: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74436.0 M-cycles
step 18150: timed with pme grid 48 48 48, coulomb cutoff 1.372: 76238.2 M-cycles
step 18250: timed with pme grid 52 52 52, coulomb cutoff 1.267: 77272.9 M-cycles
step 18350: timed with pme grid 56 56 56, coulomb cutoff 1.176: 73766.6 M-cycles
step 18450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73870.7 M-cycles
Writing checkpoint, step 18500 at Mon Jan 13 07:39:26 2020


step 18550: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71414.4 M-cycles
              optimal pme grid 52 52 52, coulomb cutoff 1.267
Writing checkpoint, step 19700 at Mon Jan 13 07:54:06 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   59249
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.460 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.460 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.506 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.52 nm Y 3.52 nm Z 3.52 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.517 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.244 nm, rlist 1.244 nm
  inner list: updated every 12 steps, buffer 0.047 nm, rlist 1.047 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 73 min 4273 max 4604

Started mdrun on rank 0 Mon Jan 13 08:13:53 2020


DD  step 19749 load imb.: force  6.3%  pme mesh/force 6.374
step 19900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 191543.1 M-cycles
step 20000: timed with pme grid 60 60 60, coulomb cutoff 1.099: 205856.9 M-cycles
step 20100: timed with pme grid 52 52 52, coulomb cutoff 1.268: 200207.6 M-cycles
step 20200: timed with pme grid 48 48 48, coulomb cutoff 1.374: 167533.6 M-cycles
Writing checkpoint, step 20200 at Mon Jan 13 08:30:12 2020


step 20300: timed with pme grid 44 44 44, coulomb cutoff 1.499: 160333.8 M-cycles
step 20300: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.499
step 20400: timed with pme grid 44 44 44, coulomb cutoff 1.499: 196448.5 M-cycles
step 20500: timed with pme grid 48 48 48, coulomb cutoff 1.374: 125674.7 M-cycles
step 20600: timed with pme grid 48 48 48, coulomb cutoff 1.374: 219301.8 M-cycles
              optimal pme grid 48 48 48, coulomb cutoff 1.374
Writing checkpoint, step 20650 at Mon Jan 13 08:44:51 2020


Writing checkpoint, step 21100 at Mon Jan 13 08:59:24 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   118248
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.451 nm, LJ-14, atoms 321 1323
  multi-body bonded interactions: 0.451 nm, Ryckaert-Bell., atoms 321 1323
Minimum cell size due to bonded interactions: 0.496 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.510 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4293 max 4594

Started mdrun on rank 0 Mon Jan 13 09:14:08 2020


DD  step 21149 load imb.: force 10.1%  pme mesh/force 6.448
step 21300: timed with pme grid 72 72 72, coulomb cutoff 1.000: 69319.3 M-cycles
step 21400: timed with pme grid 60 60 60, coulomb cutoff 1.097: 67071.3 M-cycles
step 21500: timed with pme grid 52 52 52, coulomb cutoff 1.265: 71919.6 M-cycles
step 21600: timed with pme grid 48 48 48, coulomb cutoff 1.371: 70053.0 M-cycles
step 21700: timed with pme grid 44 44 44, coulomb cutoff 1.496: 71408.5 M-cycles
step 21700: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 21800: timed with pme grid 44 44 44, coulomb cutoff 1.496: 68953.5 M-cycles
step 21900: timed with pme grid 48 48 48, coulomb cutoff 1.371: 64442.3 M-cycles
step 22000: timed with pme grid 52 52 52, coulomb cutoff 1.265: 67420.9 M-cycles
step 22100: timed with pme grid 56 56 56, coulomb cutoff 1.175: 66025.0 M-cycles
step 22200: timed with pme grid 60 60 60, coulomb cutoff 1.097: 72280.8 M-cycles
Writing checkpoint, step 22250 at Mon Jan 13 09:29:38 2020


step 22300: timed with pme grid 64 64 64, coulomb cutoff 1.028: 67841.3 M-cycles
step 22400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 67329.9 M-cycles
step 22500: timed with pme grid 44 44 44, coulomb cutoff 1.496: 68577.2 M-cycles
step 22600: timed with pme grid 48 48 48, coulomb cutoff 1.371: 65728.5 M-cycles
step 22700: timed with pme grid 52 52 52, coulomb cutoff 1.265: 67453.7 M-cycles
step 22800: timed with pme grid 56 56 56, coulomb cutoff 1.175: 67699.8 M-cycles
step 22900: timed with pme grid 60 60 60, coulomb cutoff 1.097: 61215.9 M-cycles
step 23000: timed with pme grid 64 64 64, coulomb cutoff 1.028: 64779.1 M-cycles
step 23100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 64535.4 M-cycles
step 23200: timed with pme grid 48 48 48, coulomb cutoff 1.371: 67951.9 M-cycles
step 23300: timed with pme grid 52 52 52, coulomb cutoff 1.265: 63119.5 M-cycles
step 23400: timed with pme grid 56 56 56, coulomb cutoff 1.175: 65358.5 M-cycles
Writing checkpoint, step 23400 at Mon Jan 13 09:44:49 2020


step 23500: timed with pme grid 60 60 60, coulomb cutoff 1.097: 66919.0 M-cycles
step 23600: timed with pme grid 64 64 64, coulomb cutoff 1.028: 64767.8 M-cycles
step 23700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 66690.1 M-cycles
step 23800: timed with pme grid 48 48 48, coulomb cutoff 1.371: 66058.0 M-cycles
step 23900: timed with pme grid 52 52 52, coulomb cutoff 1.265: 69914.7 M-cycles
step 24000: timed with pme grid 56 56 56, coulomb cutoff 1.175: 66772.3 M-cycles
step 24100: timed with pme grid 60 60 60, coulomb cutoff 1.097: 65013.7 M-cycles
step 24200: timed with pme grid 64 64 64, coulomb cutoff 1.028: 68138.8 M-cycles
step 24300: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62626.6 M-cycles
step 24400: timed with pme grid 48 48 48, coulomb cutoff 1.371: 62762.3 M-cycles
step 24500: timed with pme grid 52 52 52, coulomb cutoff 1.265: 67258.7 M-cycles
Writing checkpoint, step 24500 at Mon Jan 13 09:59:22 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   123325
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.462 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.462 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.508 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 67 min 4289 max 4563

Started mdrun on rank 0 Mon Jan 13 10:16:48 2020


DD  step 24549 load imb.: force  7.2%  pme mesh/force 6.631
step 24700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 68047.5 M-cycles
step 24800: timed with pme grid 60 60 60, coulomb cutoff 1.097: 73560.1 M-cycles
step 24900: timed with pme grid 52 52 52, coulomb cutoff 1.266: 72566.8 M-cycles
step 25000: timed with pme grid 48 48 48, coulomb cutoff 1.371: 73458.7 M-cycles
step 25100: timed with pme grid 44 44 44, coulomb cutoff 1.496: 72744.5 M-cycles
step 25100: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 25200: timed with pme grid 44 44 44, coulomb cutoff 1.496: 73728.1 M-cycles
step 25300: timed with pme grid 48 48 48, coulomb cutoff 1.371: 70628.3 M-cycles
step 25400: timed with pme grid 52 52 52, coulomb cutoff 1.266: 69615.2 M-cycles
step 25500: timed with pme grid 56 56 56, coulomb cutoff 1.175: 70147.4 M-cycles
step 25600: timed with pme grid 60 60 60, coulomb cutoff 1.097: 70441.6 M-cycles
step 25700: timed with pme grid 64 64 64, coulomb cutoff 1.028: 74406.2 M-cycles
Writing checkpoint, step 25700 at Mon Jan 13 10:32:13 2020


step 25800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76024.9 M-cycles
step 25900: timed with pme grid 44 44 44, coulomb cutoff 1.496: 75667.5 M-cycles
step 26000: timed with pme grid 48 48 48, coulomb cutoff 1.371: 78828.7 M-cycles
step 26100: timed with pme grid 52 52 52, coulomb cutoff 1.266: 71656.2 M-cycles
step 26200: timed with pme grid 56 56 56, coulomb cutoff 1.175: 71249.3 M-cycles
step 26300: timed with pme grid 60 60 60, coulomb cutoff 1.097: 74551.8 M-cycles
step 26400: timed with pme grid 64 64 64, coulomb cutoff 1.028: 71599.5 M-cycles
step 26500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 79481.0 M-cycles
step 26600: timed with pme grid 44 44 44, coulomb cutoff 1.496: 66324.8 M-cycles
step 26700: timed with pme grid 48 48 48, coulomb cutoff 1.371: 69063.6 M-cycles
step 26800: timed with pme grid 52 52 52, coulomb cutoff 1.266: 72424.3 M-cycles
Writing checkpoint, step 26850 at Mon Jan 13 10:47:06 2020


step 26900: timed with pme grid 56 56 56, coulomb cutoff 1.175: 73052.9 M-cycles
step 27000: timed with pme grid 60 60 60, coulomb cutoff 1.097: 71672.8 M-cycles
step 27100: timed with pme grid 64 64 64, coulomb cutoff 1.028: 73155.7 M-cycles
step 27200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72640.9 M-cycles
step 27300: timed with pme grid 44 44 44, coulomb cutoff 1.496: 74996.1 M-cycles
step 27400: timed with pme grid 48 48 48, coulomb cutoff 1.371: 72082.3 M-cycles
step 27500: timed with pme grid 52 52 52, coulomb cutoff 1.266: 73698.8 M-cycles
step 27600: timed with pme grid 56 56 56, coulomb cutoff 1.175: 70526.8 M-cycles
step 27700: timed with pme grid 60 60 60, coulomb cutoff 1.097: 76744.3 M-cycles
step 27800: timed with pme grid 64 64 64, coulomb cutoff 1.028: 69297.5 M-cycles
step 27900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70723.9 M-cycles
step 28000: timed with pme grid 44 44 44, coulomb cutoff 1.496: 68840.8 M-cycles
Writing checkpoint, step 28050 at Mon Jan 13 11:02:23 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   275511
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.503 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.515 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 61 min 4305 max 4519

Started mdrun on rank 0 Mon Jan 13 11:19:34 2020


DD  step 28099 load imb.: force  8.1%  pme mesh/force 6.524
step 28250: timed with pme grid 72 72 72, coulomb cutoff 1.000: 63434.2 M-cycles
step 28350: timed with pme grid 60 60 60, coulomb cutoff 1.098: 55380.9 M-cycles
step 28450: timed with pme grid 52 52 52, coulomb cutoff 1.267: 65527.5 M-cycles
step 28550: timed with pme grid 56 56 56, coulomb cutoff 1.177: 65658.3 M-cycles
step 28650: timed with pme grid 60 60 60, coulomb cutoff 1.098: 60194.0 M-cycles
step 28750: timed with pme grid 64 64 64, coulomb cutoff 1.030: 70053.2 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.098
Writing checkpoint, step 29300 at Mon Jan 13 11:35:05 2020


Writing checkpoint, step 30550 at Mon Jan 13 11:49:57 2020


Writing checkpoint, step 31800 at Mon Jan 13 12:04:49 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   364916
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.456 nm, LJ-14, atoms 5359 6187
  multi-body bonded interactions: 0.456 nm, Ryckaert-Bell., atoms 5359 6187
Minimum cell size due to bonded interactions: 0.501 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 62 min 4303 max 4541

Started mdrun on rank 0 Mon Jan 13 12:22:10 2020


DD  step 31849 load imb.: force 16.1%  pme mesh/force 5.918
step 32000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 64320.0 M-cycles
step 32100: timed with pme grid 60 60 60, coulomb cutoff 1.098: 62818.5 M-cycles
step 32200: timed with pme grid 52 52 52, coulomb cutoff 1.267: 62902.2 M-cycles
step 32300: timed with pme grid 48 48 48, coulomb cutoff 1.372: 59097.1 M-cycles
step 32400: timed with pme grid 44 44 44, coulomb cutoff 1.497: 66031.1 M-cycles
step 32400: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 32500: timed with pme grid 44 44 44, coulomb cutoff 1.497: 67699.5 M-cycles
step 32600: timed with pme grid 48 48 48, coulomb cutoff 1.372: 66357.6 M-cycles
step 32700: timed with pme grid 52 52 52, coulomb cutoff 1.267: 66043.8 M-cycles
step 32800: timed with pme grid 56 56 56, coulomb cutoff 1.176: 61956.6 M-cycles
step 32900: timed with pme grid 60 60 60, coulomb cutoff 1.098: 67041.2 M-cycles
step 33000: timed with pme grid 64 64 64, coulomb cutoff 1.029: 68378.8 M-cycles
Writing checkpoint, step 33000 at Mon Jan 13 12:37:41 2020


step 33100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62959.2 M-cycles
step 33200: timed with pme grid 44 44 44, coulomb cutoff 1.497: 69812.2 M-cycles
step 33300: timed with pme grid 48 48 48, coulomb cutoff 1.372: 67337.9 M-cycles
step 33400: timed with pme grid 52 52 52, coulomb cutoff 1.267: 60750.5 M-cycles
step 33500: timed with pme grid 56 56 56, coulomb cutoff 1.176: 56848.8 M-cycles
step 33600: timed with pme grid 60 60 60, coulomb cutoff 1.098: 62065.5 M-cycles
step 33700: timed with pme grid 64 64 64, coulomb cutoff 1.029: 60487.4 M-cycles
step 33800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 59095.4 M-cycles
step 33900: timed with pme grid 48 48 48, coulomb cutoff 1.372: 65976.5 M-cycles
step 34000: timed with pme grid 52 52 52, coulomb cutoff 1.267: 64185.2 M-cycles
step 34100: timed with pme grid 56 56 56, coulomb cutoff 1.176: 67253.3 M-cycles
Writing checkpoint, step 34150 at Mon Jan 13 12:52:24 2020


step 34200: timed with pme grid 60 60 60, coulomb cutoff 1.098: 60095.7 M-cycles
step 34300: timed with pme grid 64 64 64, coulomb cutoff 1.029: 69940.6 M-cycles
step 34400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 63337.2 M-cycles
step 34500: timed with pme grid 48 48 48, coulomb cutoff 1.372: 67996.9 M-cycles
step 34600: timed with pme grid 52 52 52, coulomb cutoff 1.267: 64438.2 M-cycles
step 34700: timed with pme grid 56 56 56, coulomb cutoff 1.176: 59301.1 M-cycles
step 34800: timed with pme grid 60 60 60, coulomb cutoff 1.098: 69230.5 M-cycles
step 34900: timed with pme grid 64 64 64, coulomb cutoff 1.029: 63905.3 M-cycles
step 35000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62929.4 M-cycles
              optimal pme grid 56 56 56, coulomb cutoff 1.176
Writing checkpoint, step 35300 at Mon Jan 13 13:07:23 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   345670
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.459 nm, LJ-14, atoms 2029 2976
  multi-body bonded interactions: 0.459 nm, Ryckaert-Bell., atoms 2029 2976
Minimum cell size due to bonded interactions: 0.505 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.512 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 67 min 4279 max 4568

Started mdrun on rank 0 Mon Jan 13 13:26:01 2020


DD  step 35349 load imb.: force  7.0%  pme mesh/force 6.987
step 35500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 69478.3 M-cycles
step 35600: timed with pme grid 60 60 60, coulomb cutoff 1.098: 68113.2 M-cycles
step 35700: timed with pme grid 52 52 52, coulomb cutoff 1.266: 65387.0 M-cycles
step 35800: timed with pme grid 48 48 48, coulomb cutoff 1.372: 64937.4 M-cycles
step 35900: timed with pme grid 44 44 44, coulomb cutoff 1.497: 66875.7 M-cycles
step 35900: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 36000: timed with pme grid 44 44 44, coulomb cutoff 1.497: 69394.0 M-cycles
step 36100: timed with pme grid 48 48 48, coulomb cutoff 1.372: 65279.4 M-cycles
step 36200: timed with pme grid 52 52 52, coulomb cutoff 1.266: 55126.7 M-cycles
step 36300: timed with pme grid 56 56 56, coulomb cutoff 1.176: 67146.5 M-cycles
step 36400: timed with pme grid 60 60 60, coulomb cutoff 1.098: 68523.5 M-cycles
Writing checkpoint, step 36450 at Mon Jan 13 13:41:10 2020


step 36500: timed with pme grid 64 64 64, coulomb cutoff 1.029: 72158.2 M-cycles
step 36600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 65519.1 M-cycles
step 36700: timed with pme grid 52 52 52, coulomb cutoff 1.266: 70852.3 M-cycles
              optimal pme grid 52 52 52, coulomb cutoff 1.266
Writing checkpoint, step 37600 at Mon Jan 13 13:56:31 2020


Writing checkpoint, step 38750 at Mon Jan 13 14:11:34 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   307699
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.503 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.52 nm Y 3.52 nm Z 3.52 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.516 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.244 nm, rlist 1.244 nm
  inner list: updated every 12 steps, buffer 0.047 nm, rlist 1.047 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 78 min 4264 max 4603

Started mdrun on rank 0 Mon Jan 13 14:29:19 2020


DD  step 38799 load imb.: force  8.1%  pme mesh/force 7.348
step 38950: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72424.9 M-cycles
step 39050: timed with pme grid 60 60 60, coulomb cutoff 1.099: 74010.0 M-cycles
step 39150: timed with pme grid 52 52 52, coulomb cutoff 1.268: 69052.4 M-cycles
step 39250: timed with pme grid 48 48 48, coulomb cutoff 1.374: 67378.3 M-cycles
step 39350: timed with pme grid 44 44 44, coulomb cutoff 1.498: 65431.2 M-cycles
step 39350: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.498
step 39450: timed with pme grid 44 44 44, coulomb cutoff 1.498: 74168.2 M-cycles
step 39550: timed with pme grid 48 48 48, coulomb cutoff 1.374: 72330.9 M-cycles
step 39650: timed with pme grid 52 52 52, coulomb cutoff 1.268: 78162.3 M-cycles
step 39750: timed with pme grid 56 56 56, coulomb cutoff 1.177: 71858.1 M-cycles
step 39850: timed with pme grid 64 64 64, coulomb cutoff 1.030: 75504.6 M-cycles
step 39950: timed with pme grid 72 72 72, coulomb cutoff 1.000: 68972.7 M-cycles
Writing checkpoint, step 39950 at Mon Jan 13 14:44:30 2020


step 40050: timed with pme grid 44 44 44, coulomb cutoff 1.498: 76793.3 M-cycles
step 40150: timed with pme grid 48 48 48, coulomb cutoff 1.374: 72318.2 M-cycles
step 40250: timed with pme grid 52 52 52, coulomb cutoff 1.268: 74297.9 M-cycles
step 40350: timed with pme grid 56 56 56, coulomb cutoff 1.177: 74372.8 M-cycles
step 40450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 67568.8 M-cycles
step 40550: timed with pme grid 44 44 44, coulomb cutoff 1.498: 74398.0 M-cycles
step 40650: timed with pme grid 48 48 48, coulomb cutoff 1.374: 74822.6 M-cycles
step 40750: timed with pme grid 52 52 52, coulomb cutoff 1.268: 71106.1 M-cycles
step 40850: timed with pme grid 56 56 56, coulomb cutoff 1.177: 70753.3 M-cycles
step 40950: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74064.6 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.498
Writing checkpoint, step 41150 at Mon Jan 13 14:59:50 2020


Writing checkpoint, step 42400 at Mon Jan 13 15:14:53 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   139456
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 2029 2976
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 2029 2976
Minimum cell size due to bonded interactions: 0.503 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 73 min 4280 max 4583

Started mdrun on rank 0 Mon Jan 13 15:31:57 2020


DD  step 42449 load imb.: force 11.7%  pme mesh/force 6.143
step 42600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 59807.1 M-cycles
step 42700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64718.7 M-cycles
step 42800: timed with pme grid 52 52 52, coulomb cutoff 1.267: 65639.3 M-cycles
step 42900: timed with pme grid 48 48 48, coulomb cutoff 1.372: 66390.2 M-cycles
step 43000: timed with pme grid 44 44 44, coulomb cutoff 1.497: 64514.1 M-cycles
step 43000: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 43100: timed with pme grid 44 44 44, coulomb cutoff 1.497: 68776.1 M-cycles
step 43200: timed with pme grid 48 48 48, coulomb cutoff 1.372: 62484.7 M-cycles
step 43300: timed with pme grid 52 52 52, coulomb cutoff 1.267: 61166.8 M-cycles
step 43400: timed with pme grid 56 56 56, coulomb cutoff 1.176: 65912.3 M-cycles
step 43500: timed with pme grid 60 60 60, coulomb cutoff 1.098: 61736.4 M-cycles
step 43600: timed with pme grid 64 64 64, coulomb cutoff 1.029: 67931.9 M-cycles
Writing checkpoint, step 43600 at Mon Jan 13 15:47:33 2020


step 43700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 63614.2 M-cycles
step 43800: timed with pme grid 44 44 44, coulomb cutoff 1.497: 62258.4 M-cycles
step 43900: timed with pme grid 48 48 48, coulomb cutoff 1.372: 53754.6 M-cycles
step 44000: timed with pme grid 52 52 52, coulomb cutoff 1.267: 63753.2 M-cycles
step 44100: timed with pme grid 56 56 56, coulomb cutoff 1.176: 66137.9 M-cycles
step 44200: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64351.7 M-cycles
step 44300: timed with pme grid 64 64 64, coulomb cutoff 1.029: 67205.1 M-cycles
step 44400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 63194.3 M-cycles
step 44500: timed with pme grid 48 48 48, coulomb cutoff 1.372: 65945.6 M-cycles
step 44600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 66573.9 M-cycles
              optimal pme grid 48 48 48, coulomb cutoff 1.372
Writing checkpoint, step 44750 at Mon Jan 13 16:02:15 2020


Writing checkpoint, step 46000 at Mon Jan 13 16:17:32 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   171963
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.455 nm, LJ-14, atoms 5359 6187
  multi-body bonded interactions: 0.455 nm, Ryckaert-Bell., atoms 5359 6187
Minimum cell size due to bonded interactions: 0.500 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 63 min 4292 max 4509

Started mdrun on rank 0 Mon Jan 13 16:35:14 2020


DD  step 46049 load imb.: force  5.8%  pme mesh/force 6.468
step 46200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 77562.5 M-cycles
step 46300: timed with pme grid 60 60 60, coulomb cutoff 1.097: 90470.0 M-cycles
step 46400: timed with pme grid 64 64 64, coulomb cutoff 1.029: 68347.0 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.029
Writing checkpoint, step 47100 at Mon Jan 13 16:50:55 2020


Writing checkpoint, step 48150 at Mon Jan 13 17:06:04 2020


Writing checkpoint, step 49250 at Mon Jan 13 17:20:45 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   306664
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.502 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.512 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 66 min 4277 max 4539

Started mdrun on rank 0 Mon Jan 13 17:48:24 2020


DD  step 49299 load imb.: force  8.5%  pme mesh/force 6.589
step 49450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 79044.0 M-cycles
step 49550: timed with pme grid 60 60 60, coulomb cutoff 1.097: 104436.8 M-cycles
step 49650: timed with pme grid 64 64 64, coulomb cutoff 1.029: 66416.4 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.029

DD  step 49999 load imb.: force  6.0%  pme mesh/force 4.144
           Step           Time
          50000      100.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Ryckaert-Bell.          LJ-14     Coulomb-14
    1.37054e+04    8.06023e+02    6.18603e+03    9.63961e+03    5.16698e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    3.26714e+05   -1.58246e+04   -2.24048e+06    9.47785e+03   -1.83811e+06
    Kinetic En.   Total Energy  Conserved En.    Temperature Pres. DC (bar)
    2.95803e+05   -1.54230e+06   -1.54754e+06    3.01836e+02   -2.24611e+02
 Pressure (bar)   Constr. rmsd
   -9.92545e+01    2.91661e-05

Writing checkpoint, step 50150 at Mon Jan 13 18:04:06 2020


Writing checkpoint, step 51150 at Mon Jan 13 18:19:06 2020


Writing checkpoint, step 52150 at Mon Jan 13 18:33:39 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   400241
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.462 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.462 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.509 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.52 nm Y 3.52 nm Z 3.52 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.515 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 72 min 4276 max 4585

Started mdrun on rank 0 Mon Jan 13 18:54:54 2020


DD  step 52199 load imb.: force  5.2%  pme mesh/force 6.663
step 52350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 69126.3 M-cycles
step 52450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64774.0 M-cycles
step 52550: timed with pme grid 52 52 52, coulomb cutoff 1.267: 64865.3 M-cycles
step 52650: timed with pme grid 48 48 48, coulomb cutoff 1.373: 67340.4 M-cycles
step 52750: timed with pme grid 44 44 44, coulomb cutoff 1.498: 68111.2 M-cycles
step 52750: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.498
step 52850: timed with pme grid 44 44 44, coulomb cutoff 1.498: 65541.6 M-cycles
step 52950: timed with pme grid 48 48 48, coulomb cutoff 1.373: 65828.2 M-cycles
step 53050: timed with pme grid 52 52 52, coulomb cutoff 1.267: 73376.9 M-cycles
step 53150: timed with pme grid 56 56 56, coulomb cutoff 1.177: 61825.7 M-cycles
step 53250: timed with pme grid 60 60 60, coulomb cutoff 1.098: 62126.7 M-cycles
Writing checkpoint, step 53300 at Mon Jan 13 19:10:12 2020


step 53350: timed with pme grid 64 64 64, coulomb cutoff 1.030: 63714.8 M-cycles
step 53450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62796.9 M-cycles
step 53550: timed with pme grid 44 44 44, coulomb cutoff 1.498: 64349.2 M-cycles
step 53650: timed with pme grid 48 48 48, coulomb cutoff 1.373: 63001.5 M-cycles
step 53750: timed with pme grid 52 52 52, coulomb cutoff 1.267: 69760.2 M-cycles
step 53850: timed with pme grid 56 56 56, coulomb cutoff 1.177: 68696.2 M-cycles
step 53950: timed with pme grid 60 60 60, coulomb cutoff 1.098: 65462.1 M-cycles
step 54050: timed with pme grid 64 64 64, coulomb cutoff 1.030: 66596.5 M-cycles
step 54150: timed with pme grid 72 72 72, coulomb cutoff 1.000: 65946.5 M-cycles
step 54250: timed with pme grid 44 44 44, coulomb cutoff 1.498: 65672.9 M-cycles
step 54350: timed with pme grid 48 48 48, coulomb cutoff 1.373: 67377.1 M-cycles
step 54450: timed with pme grid 52 52 52, coulomb cutoff 1.267: 66647.6 M-cycles
Writing checkpoint, step 54450 at Mon Jan 13 19:25:21 2020


step 54550: timed with pme grid 56 56 56, coulomb cutoff 1.177: 66470.5 M-cycles
step 54650: timed with pme grid 60 60 60, coulomb cutoff 1.098: 65262.9 M-cycles
step 54750: timed with pme grid 64 64 64, coulomb cutoff 1.030: 68711.3 M-cycles
step 54850: timed with pme grid 72 72 72, coulomb cutoff 1.000: 64988.9 M-cycles
              optimal pme grid 56 56 56, coulomb cutoff 1.177
Writing checkpoint, step 55600 at Mon Jan 13 19:40:07 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   442849
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.462 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.462 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.508 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 74 min 4279 max 4566

Started mdrun on rank 0 Mon Jan 13 19:57:33 2020


DD  step 55649 load imb.: force  5.6%  pme mesh/force 6.105
step 55800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74796.2 M-cycles
step 55900: timed with pme grid 60 60 60, coulomb cutoff 1.098: 75738.3 M-cycles
step 56000: timed with pme grid 52 52 52, coulomb cutoff 1.267: 76883.3 M-cycles
step 56100: timed with pme grid 48 48 48, coulomb cutoff 1.373: 70471.8 M-cycles
step 56200: timed with pme grid 44 44 44, coulomb cutoff 1.497: 70003.6 M-cycles
step 56200: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 56300: timed with pme grid 44 44 44, coulomb cutoff 1.497: 68441.3 M-cycles
step 56400: timed with pme grid 48 48 48, coulomb cutoff 1.373: 69448.3 M-cycles
step 56500: timed with pme grid 52 52 52, coulomb cutoff 1.267: 76395.3 M-cycles
step 56600: timed with pme grid 56 56 56, coulomb cutoff 1.176: 72341.2 M-cycles
step 56700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 65300.3 M-cycles
step 56800: timed with pme grid 64 64 64, coulomb cutoff 1.029: 73312.8 M-cycles
Writing checkpoint, step 56800 at Mon Jan 13 20:13:14 2020


step 56900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74578.5 M-cycles
step 57000: timed with pme grid 44 44 44, coulomb cutoff 1.497: 78226.0 M-cycles
step 57100: timed with pme grid 48 48 48, coulomb cutoff 1.373: 65737.8 M-cycles
step 57200: timed with pme grid 52 52 52, coulomb cutoff 1.267: 76728.4 M-cycles
step 57300: timed with pme grid 56 56 56, coulomb cutoff 1.176: 66797.7 M-cycles
step 57400: timed with pme grid 60 60 60, coulomb cutoff 1.098: 68577.2 M-cycles
step 57500: timed with pme grid 64 64 64, coulomb cutoff 1.029: 74339.8 M-cycles
step 57600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70765.2 M-cycles
step 57700: timed with pme grid 44 44 44, coulomb cutoff 1.497: 71162.6 M-cycles
step 57800: timed with pme grid 48 48 48, coulomb cutoff 1.373: 72816.6 M-cycles
step 57900: timed with pme grid 56 56 56, coulomb cutoff 1.176: 71968.1 M-cycles
Writing checkpoint, step 57950 at Mon Jan 13 20:28:14 2020


step 58000: timed with pme grid 60 60 60, coulomb cutoff 1.098: 69034.0 M-cycles
step 58100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73013.6 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.098
Writing checkpoint, step 59150 at Mon Jan 13 20:43:09 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   429984
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.461 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.461 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.507 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 64 min 4294 max 4533

Started mdrun on rank 0 Mon Jan 13 21:00:53 2020


DD  step 59199 load imb.: force  8.7%  pme mesh/force 5.839
step 59350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 75101.1 M-cycles
step 59450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 76043.8 M-cycles
step 59550: timed with pme grid 52 52 52, coulomb cutoff 1.267: 85530.1 M-cycles
step 59650: timed with pme grid 56 56 56, coulomb cutoff 1.176: 89375.6 M-cycles
step 59750: timed with pme grid 60 60 60, coulomb cutoff 1.098: 99262.0 M-cycles
step 59850: timed with pme grid 64 64 64, coulomb cutoff 1.029: 96920.5 M-cycles
step 59950: timed with pme grid 72 72 72, coulomb cutoff 1.000: 80515.9 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 60150 at Mon Jan 13 21:16:25 2020


Writing checkpoint, step 61250 at Mon Jan 13 21:31:14 2020


Writing checkpoint, step 62400 at Mon Jan 13 21:46:23 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   56440
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.459 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.459 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.504 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.510 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 67 min 4280 max 4541

Started mdrun on rank 0 Mon Jan 13 22:03:33 2020


DD  step 62449 load imb.: force  8.1%  pme mesh/force 6.078
step 62600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71439.9 M-cycles
step 62700: timed with pme grid 60 60 60, coulomb cutoff 1.097: 71211.2 M-cycles
step 62800: timed with pme grid 52 52 52, coulomb cutoff 1.266: 71609.6 M-cycles
step 62900: timed with pme grid 48 48 48, coulomb cutoff 1.371: 70622.0 M-cycles
step 63000: timed with pme grid 44 44 44, coulomb cutoff 1.496: 70392.9 M-cycles
step 63000: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 63100: timed with pme grid 44 44 44, coulomb cutoff 1.496: 74957.0 M-cycles
step 63200: timed with pme grid 48 48 48, coulomb cutoff 1.371: 71970.4 M-cycles
step 63300: timed with pme grid 52 52 52, coulomb cutoff 1.266: 77305.9 M-cycles
step 63400: timed with pme grid 56 56 56, coulomb cutoff 1.175: 71986.8 M-cycles
step 63500: timed with pme grid 60 60 60, coulomb cutoff 1.097: 79979.9 M-cycles
step 63600: timed with pme grid 64 64 64, coulomb cutoff 1.028: 74267.4 M-cycles
Writing checkpoint, step 63600 at Mon Jan 13 22:19:12 2020


step 63700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72838.4 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.496
Writing checkpoint, step 64750 at Mon Jan 13 22:33:43 2020


Writing checkpoint, step 65950 at Mon Jan 13 22:49:09 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   141955
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.458 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.458 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.504 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 71 min 4275 max 4576

Started mdrun on rank 0 Mon Jan 13 23:09:14 2020


DD  step 65999 load imb.: force  8.4%  pme mesh/force 5.518
step 66150: timed with pme grid 72 72 72, coulomb cutoff 1.000: 75031.4 M-cycles
step 66250: timed with pme grid 60 60 60, coulomb cutoff 1.098: 72623.0 M-cycles
step 66350: timed with pme grid 52 52 52, coulomb cutoff 1.267: 71619.0 M-cycles
step 66450: timed with pme grid 48 48 48, coulomb cutoff 1.373: 74911.1 M-cycles
step 66550: timed with pme grid 44 44 44, coulomb cutoff 1.497: 78705.9 M-cycles
step 66550: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 66650: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74126.2 M-cycles
step 66750: timed with pme grid 48 48 48, coulomb cutoff 1.373: 71944.1 M-cycles
step 66850: timed with pme grid 52 52 52, coulomb cutoff 1.267: 73654.7 M-cycles
step 66950: timed with pme grid 56 56 56, coulomb cutoff 1.176: 82536.5 M-cycles
step 67050: timed with pme grid 60 60 60, coulomb cutoff 1.098: 71260.0 M-cycles
Writing checkpoint, step 67100 at Mon Jan 13 23:24:31 2020


step 67150: timed with pme grid 64 64 64, coulomb cutoff 1.029: 72655.4 M-cycles
step 67250: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70919.6 M-cycles
step 67350: timed with pme grid 44 44 44, coulomb cutoff 1.497: 80492.1 M-cycles
step 67450: timed with pme grid 48 48 48, coulomb cutoff 1.373: 69377.9 M-cycles
step 67550: timed with pme grid 52 52 52, coulomb cutoff 1.267: 70173.8 M-cycles
step 67650: timed with pme grid 56 56 56, coulomb cutoff 1.176: 80295.4 M-cycles
step 67750: timed with pme grid 60 60 60, coulomb cutoff 1.098: 70876.9 M-cycles
step 67850: timed with pme grid 64 64 64, coulomb cutoff 1.029: 76797.5 M-cycles
step 67950: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70512.2 M-cycles
step 68050: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74696.5 M-cycles
step 68150: timed with pme grid 48 48 48, coulomb cutoff 1.373: 73753.2 M-cycles
step 68250: timed with pme grid 52 52 52, coulomb cutoff 1.267: 74720.3 M-cycles
Writing checkpoint, step 68250 at Mon Jan 13 23:39:33 2020


step 68350: timed with pme grid 60 60 60, coulomb cutoff 1.098: 66848.9 M-cycles
step 68450: timed with pme grid 64 64 64, coulomb cutoff 1.029: 74049.2 M-cycles
step 68550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 77322.8 M-cycles
step 68650: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74711.9 M-cycles
step 68750: timed with pme grid 48 48 48, coulomb cutoff 1.373: 76176.1 M-cycles
step 68850: timed with pme grid 52 52 52, coulomb cutoff 1.267: 73215.7 M-cycles
step 68950: timed with pme grid 60 60 60, coulomb cutoff 1.098: 76229.2 M-cycles
step 69050: timed with pme grid 64 64 64, coulomb cutoff 1.029: 75908.9 M-cycles
step 69150: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74112.0 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.098
Writing checkpoint, step 69400 at Mon Jan 13 23:54:25 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   257162
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 5359 6187
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 5359 6187
Minimum cell size due to bonded interactions: 0.503 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 62 min 4290 max 4519

Started mdrun on rank 0 Tue Jan 14 00:16:05 2020


DD  step 69449 load imb.: force  5.0%  pme mesh/force 6.774
step 69600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72602.0 M-cycles
step 69700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 69564.0 M-cycles
step 69800: timed with pme grid 52 52 52, coulomb cutoff 1.267: 73061.0 M-cycles
step 69900: timed with pme grid 48 48 48, coulomb cutoff 1.373: 74926.2 M-cycles
step 70000: timed with pme grid 44 44 44, coulomb cutoff 1.497: 66599.0 M-cycles
step 70000: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 70100: timed with pme grid 44 44 44, coulomb cutoff 1.497: 67342.5 M-cycles
step 70200: timed with pme grid 52 52 52, coulomb cutoff 1.267: 71028.9 M-cycles
step 70300: timed with pme grid 56 56 56, coulomb cutoff 1.177: 74500.3 M-cycles
step 70400: timed with pme grid 60 60 60, coulomb cutoff 1.098: 69702.9 M-cycles
step 70500: timed with pme grid 64 64 64, coulomb cutoff 1.029: 75687.4 M-cycles
step 70600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 75218.5 M-cycles
Writing checkpoint, step 70600 at Tue Jan 14 00:31:26 2020


step 70700: timed with pme grid 44 44 44, coulomb cutoff 1.497: 76161.7 M-cycles
step 70800: timed with pme grid 52 52 52, coulomb cutoff 1.267: 72756.9 M-cycles
step 70900: timed with pme grid 56 56 56, coulomb cutoff 1.177: 72576.4 M-cycles
step 71000: timed with pme grid 60 60 60, coulomb cutoff 1.098: 69968.8 M-cycles
step 71100: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71050.2 M-cycles
step 71200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 68744.8 M-cycles
step 71300: timed with pme grid 44 44 44, coulomb cutoff 1.497: 72331.8 M-cycles
step 71400: timed with pme grid 52 52 52, coulomb cutoff 1.267: 69182.8 M-cycles
step 71500: timed with pme grid 56 56 56, coulomb cutoff 1.177: 71671.5 M-cycles
step 71600: timed with pme grid 60 60 60, coulomb cutoff 1.098: 67328.7 M-cycles
step 71700: timed with pme grid 64 64 64, coulomb cutoff 1.029: 69094.8 M-cycles
step 71800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 78685.6 M-cycles
Writing checkpoint, step 71800 at Tue Jan 14 00:46:43 2020


step 71900: timed with pme grid 44 44 44, coulomb cutoff 1.497: 70524.0 M-cycles
step 72000: timed with pme grid 52 52 52, coulomb cutoff 1.267: 69468.2 M-cycles
step 72100: timed with pme grid 56 56 56, coulomb cutoff 1.177: 75932.2 M-cycles
step 72200: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73783.4 M-cycles
step 72300: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71833.1 M-cycles
step 72400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73146.7 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.497
Writing checkpoint, step 72950 at Tue Jan 14 01:01:15 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   106479
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.455 nm, LJ-14, atoms 5359 6187
  multi-body bonded interactions: 0.455 nm, Ryckaert-Bell., atoms 5359 6187
Minimum cell size due to bonded interactions: 0.501 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4250 max 4534

Started mdrun on rank 0 Tue Jan 14 01:19:26 2020


DD  step 72999 load imb.: force  8.0%  pme mesh/force 5.402
step 73150: timed with pme grid 72 72 72, coulomb cutoff 1.000: 82661.9 M-cycles
step 73250: timed with pme grid 60 60 60, coulomb cutoff 1.097: 109231.0 M-cycles
step 73350: timed with pme grid 64 64 64, coulomb cutoff 1.029: 84274.0 M-cycles
step 73450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 99367.5 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 73850 at Tue Jan 14 01:34:39 2020


Writing checkpoint, step 74750 at Tue Jan 14 01:50:28 2020


Writing checkpoint, step 75550 at Tue Jan 14 02:05:07 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   450065
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.458 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.458 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.504 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 62 min 4286 max 4530

Started mdrun on rank 0 Tue Jan 14 02:23:07 2020


DD  step 75599 load imb.: force  8.2%  pme mesh/force 8.806
step 75750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 111045.4 M-cycles
step 75850: timed with pme grid 60 60 60, coulomb cutoff 1.098: 135740.7 M-cycles
step 75950: timed with pme grid 64 64 64, coulomb cutoff 1.030: 150029.9 M-cycles
step 76050: timed with pme grid 72 72 72, coulomb cutoff 1.000: 130317.6 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 76150 at Tue Jan 14 02:38:32 2020


Writing checkpoint, step 76700 at Tue Jan 14 02:53:38 2020


Writing checkpoint, step 77350 at Tue Jan 14 03:08:39 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   447146
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.454 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.454 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.500 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.512 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 63 min 4299 max 4533

Started mdrun on rank 0 Tue Jan 14 03:23:22 2020


DD  step 77399 load imb.: force  6.2%  pme mesh/force 5.590
step 77550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62039.9 M-cycles
step 77650: timed with pme grid 60 60 60, coulomb cutoff 1.098: 65278.5 M-cycles
step 77750: timed with pme grid 52 52 52, coulomb cutoff 1.266: 67333.6 M-cycles
step 77850: timed with pme grid 48 48 48, coulomb cutoff 1.372: 64407.5 M-cycles
step 77950: timed with pme grid 44 44 44, coulomb cutoff 1.497: 70516.6 M-cycles
step 78050: timed with pme grid 48 48 48, coulomb cutoff 1.372: 67371.0 M-cycles
step 78150: timed with pme grid 52 52 52, coulomb cutoff 1.266: 61909.2 M-cycles
step 78250: timed with pme grid 56 56 56, coulomb cutoff 1.176: 69965.6 M-cycles
step 78350: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64944.0 M-cycles
step 78450: timed with pme grid 64 64 64, coulomb cutoff 1.029: 59888.8 M-cycles
step 78550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62581.3 M-cycles
Writing checkpoint, step 78550 at Tue Jan 14 03:38:44 2020


step 78650: timed with pme grid 48 48 48, coulomb cutoff 1.372: 66234.6 M-cycles
step 78750: timed with pme grid 52 52 52, coulomb cutoff 1.266: 69678.1 M-cycles
step 78850: timed with pme grid 60 60 60, coulomb cutoff 1.098: 69325.8 M-cycles
step 78950: timed with pme grid 64 64 64, coulomb cutoff 1.029: 67025.8 M-cycles
step 79050: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62461.6 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.029
Writing checkpoint, step 79750 at Tue Jan 14 03:53:37 2020


Writing checkpoint, step 81000 at Tue Jan 14 04:08:41 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   12593
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.456 nm, LJ-14, atoms 2034 2971
  multi-body bonded interactions: 0.456 nm, Ryckaert-Bell., atoms 2971 2034
Minimum cell size due to bonded interactions: 0.502 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.52 nm Y 3.52 nm Z 3.52 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.515 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 64 min 4285 max 4533

Started mdrun on rank 0 Tue Jan 14 04:26:38 2020


DD  step 81049 load imb.: force 10.2%  pme mesh/force 4.780
step 81200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 65196.0 M-cycles
step 81300: timed with pme grid 60 60 60, coulomb cutoff 1.099: 75693.1 M-cycles
step 81400: timed with pme grid 64 64 64, coulomb cutoff 1.030: 73717.7 M-cycles
step 81500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76316.2 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 82200 at Tue Jan 14 04:42:15 2020


Writing checkpoint, step 83350 at Tue Jan 14 04:57:00 2020


Writing checkpoint, step 84550 at Tue Jan 14 05:12:02 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   384130
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.461 nm, LJ-14, atoms 321 1323
  multi-body bonded interactions: 0.461 nm, Ryckaert-Bell., atoms 321 1323
Minimum cell size due to bonded interactions: 0.507 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 59 min 4312 max 4532

Started mdrun on rank 0 Tue Jan 14 05:30:23 2020


DD  step 84599 load imb.: force  5.1%  pme mesh/force 5.991
step 84750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 133823.5 M-cycles
step 84850: timed with pme grid 60 60 60, coulomb cutoff 1.098: 166557.3 M-cycles
step 84950: timed with pme grid 64 64 64, coulomb cutoff 1.029: 184850.7 M-cycles
step 85050: timed with pme grid 72 72 72, coulomb cutoff 1.000: 144340.3 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 85100 at Tue Jan 14 05:45:59 2020


Writing checkpoint, step 85650 at Tue Jan 14 06:02:12 2020


Writing checkpoint, step 86150 at Tue Jan 14 06:16:52 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   64078
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.458 nm, LJ-14, atoms 3581 4708
  multi-body bonded interactions: 0.458 nm, Ryckaert-Bell., atoms 4708 3581
Minimum cell size due to bonded interactions: 0.504 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4278 max 4534

Started mdrun on rank 0 Tue Jan 14 08:23:16 2020


DD  step 86199 load imb.: force 11.0%  pme mesh/force 5.852
step 86350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76281.8 M-cycles
step 86450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 70755.1 M-cycles
step 86550: timed with pme grid 52 52 52, coulomb cutoff 1.267: 70878.7 M-cycles
step 86650: timed with pme grid 48 48 48, coulomb cutoff 1.373: 71508.7 M-cycles
step 86750: timed with pme grid 44 44 44, coulomb cutoff 1.497: 69809.1 M-cycles
step 86750: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 86850: timed with pme grid 44 44 44, coulomb cutoff 1.497: 73463.3 M-cycles
step 86950: timed with pme grid 48 48 48, coulomb cutoff 1.373: 72454.0 M-cycles
step 87050: timed with pme grid 52 52 52, coulomb cutoff 1.267: 62933.4 M-cycles
step 87150: timed with pme grid 56 56 56, coulomb cutoff 1.176: 72946.9 M-cycles
step 87250: timed with pme grid 60 60 60, coulomb cutoff 1.098: 70359.8 M-cycles
step 87350: timed with pme grid 64 64 64, coulomb cutoff 1.029: 74921.8 M-cycles
Writing checkpoint, step 87350 at Tue Jan 14 08:38:56 2020


step 87450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 66768.7 M-cycles
step 87550: timed with pme grid 44 44 44, coulomb cutoff 1.497: 72376.3 M-cycles
step 87650: timed with pme grid 52 52 52, coulomb cutoff 1.267: 66659.6 M-cycles
step 87750: timed with pme grid 60 60 60, coulomb cutoff 1.098: 74983.3 M-cycles
step 87850: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72897.4 M-cycles
              optimal pme grid 52 52 52, coulomb cutoff 1.267
Writing checkpoint, step 88550 at Tue Jan 14 08:53:53 2020


Writing checkpoint, step 89800 at Tue Jan 14 09:08:38 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   250306
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.456 nm, LJ-14, atoms 3581 4708
  multi-body bonded interactions: 0.456 nm, Ryckaert-Bell., atoms 4708 3581
Minimum cell size due to bonded interactions: 0.502 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 66 min 4265 max 4533

Started mdrun on rank 0 Tue Jan 14 09:28:05 2020


DD  step 89849 load imb.: force  5.6%  pme mesh/force 4.999
step 90000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 197793.4 M-cycles
step 90100: timed with pme grid 60 60 60, coulomb cutoff 1.098: 233430.5 M-cycles
step 90200: timed with pme grid 64 64 64, coulomb cutoff 1.029: 272073.5 M-cycles
Writing checkpoint, step 90250 at Tue Jan 14 09:44:56 2020


step 90300: timed with pme grid 72 72 72, coulomb cutoff 1.000: 243060.3 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 90650 at Tue Jan 14 09:59:16 2020


Writing checkpoint, step 91150 at Tue Jan 14 10:14:18 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   52437
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.462 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.462 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.508 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 71 min 4239 max 4560

Started mdrun on rank 0 Tue Jan 14 10:28:22 2020


DD  step 91199 load imb.: force 12.0%  pme mesh/force 7.329
step 91350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 67616.8 M-cycles
step 91450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 66994.8 M-cycles
step 91550: timed with pme grid 52 52 52, coulomb cutoff 1.267: 64931.0 M-cycles
step 91650: timed with pme grid 48 48 48, coulomb cutoff 1.373: 64829.3 M-cycles
step 91750: timed with pme grid 44 44 44, coulomb cutoff 1.497: 58497.9 M-cycles
step 91750: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 91850: timed with pme grid 44 44 44, coulomb cutoff 1.497: 67450.9 M-cycles
step 91950: timed with pme grid 48 48 48, coulomb cutoff 1.373: 68470.5 M-cycles
step 92050: timed with pme grid 52 52 52, coulomb cutoff 1.267: 68209.6 M-cycles
step 92150: timed with pme grid 56 56 56, coulomb cutoff 1.177: 65398.1 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.497
Writing checkpoint, step 92300 at Tue Jan 14 10:43:32 2020


Writing checkpoint, step 93450 at Tue Jan 14 10:58:34 2020


Writing checkpoint, step 94600 at Tue Jan 14 11:13:38 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   38656
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.452 nm, LJ-14, atoms 5359 6187
  multi-body bonded interactions: 0.452 nm, Ryckaert-Bell., atoms 5359 6187
Minimum cell size due to bonded interactions: 0.498 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4280 max 4563

Started mdrun on rank 0 Tue Jan 14 11:32:54 2020


DD  step 94649 load imb.: force  6.2%  pme mesh/force 2.940
step 94800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 131468.8 M-cycles
step 94900: timed with pme grid 60 60 60, coulomb cutoff 1.098: 154502.0 M-cycles
step 95000: timed with pme grid 64 64 64, coulomb cutoff 1.029: 274167.5 M-cycles
step 95100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 194403.1 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 95150 at Tue Jan 14 11:49:38 2020


Writing checkpoint, step 95400 at Tue Jan 14 12:05:01 2020


Writing checkpoint, step 95800 at Tue Jan 14 12:18:44 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   156766
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.458 nm, LJ-14, atoms 3581 4708
  multi-body bonded interactions: 0.458 nm, Ryckaert-Bell., atoms 4708 3581
Minimum cell size due to bonded interactions: 0.504 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 63 min 4287 max 4502

Started mdrun on rank 0 Tue Jan 14 12:35:17 2020


DD  step 95849 load imb.: force  9.0%  pme mesh/force 2.314
step 96000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 91759.4 M-cycles
step 96100: timed with pme grid 60 60 60, coulomb cutoff 1.098: 261802.2 M-cycles
step 96200: timed with pme grid 64 64 64, coulomb cutoff 1.029: 260482.0 M-cycles
step 96300: timed with pme grid 72 72 72, coulomb cutoff 1.000: 232654.4 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 96350 at Tue Jan 14 12:51:40 2020


Writing checkpoint, step 96800 at Tue Jan 14 13:06:04 2020


Writing checkpoint, step 97250 at Tue Jan 14 13:22:01 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   133161
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.463 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.463 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.510 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 65 min 4269 max 4507

Started mdrun on rank 0 Tue Jan 14 13:36:33 2020


DD  step 97299 load imb.: force  6.6%  pme mesh/force 6.411
step 97450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76496.7 M-cycles
step 97550: timed with pme grid 60 60 60, coulomb cutoff 1.097: 69181.6 M-cycles
step 97650: timed with pme grid 52 52 52, coulomb cutoff 1.266: 72730.5 M-cycles
step 97750: timed with pme grid 48 48 48, coulomb cutoff 1.372: 71512.8 M-cycles
step 97850: timed with pme grid 44 44 44, coulomb cutoff 1.496: 70484.2 M-cycles
step 97850: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 97950: timed with pme grid 44 44 44, coulomb cutoff 1.496: 73328.5 M-cycles
step 98050: timed with pme grid 48 48 48, coulomb cutoff 1.372: 77605.8 M-cycles
step 98150: timed with pme grid 52 52 52, coulomb cutoff 1.266: 72671.8 M-cycles
step 98250: timed with pme grid 56 56 56, coulomb cutoff 1.176: 69533.9 M-cycles
step 98350: timed with pme grid 60 60 60, coulomb cutoff 1.097: 75084.1 M-cycles
step 98450: timed with pme grid 64 64 64, coulomb cutoff 1.029: 69575.1 M-cycles
Writing checkpoint, step 98450 at Tue Jan 14 13:52:04 2020


step 98550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 69874.4 M-cycles
step 98650: timed with pme grid 44 44 44, coulomb cutoff 1.496: 75772.4 M-cycles
step 98750: timed with pme grid 48 48 48, coulomb cutoff 1.372: 74356.9 M-cycles
step 98850: timed with pme grid 52 52 52, coulomb cutoff 1.266: 71615.7 M-cycles
step 98950: timed with pme grid 56 56 56, coulomb cutoff 1.176: 78739.8 M-cycles
step 99050: timed with pme grid 60 60 60, coulomb cutoff 1.097: 74406.8 M-cycles
step 99150: timed with pme grid 64 64 64, coulomb cutoff 1.029: 70369.0 M-cycles
step 99250: timed with pme grid 72 72 72, coulomb cutoff 1.000: 77510.6 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.097
Writing checkpoint, step 99600 at Tue Jan 14 14:06:48 2020



DD  step 99999 load imb.: force  8.2%  pme mesh/force 5.240
           Step           Time
         100000      200.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Ryckaert-Bell.          LJ-14     Coulomb-14
    1.35223e+04    7.27989e+02    5.96646e+03    9.72049e+03    5.17920e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    3.28877e+05   -1.58645e+04   -2.24199e+06    7.49706e+03   -1.83975e+06
    Kinetic En.   Total Energy  Conserved En.    Temperature Pres. DC (bar)
    2.94058e+05   -1.54569e+06   -1.55028e+06    3.00056e+02   -2.25742e+02
 Pressure (bar)   Constr. rmsd
    7.23306e+01    2.80590e-05

Writing checkpoint, step 100800 at Tue Jan 14 14:22:13 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   422403
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.455 nm, LJ-14, atoms 321 1323
  multi-body bonded interactions: 0.455 nm, Ryckaert-Bell., atoms 321 1323
Minimum cell size due to bonded interactions: 0.501 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 62 min 4290 max 4518

Started mdrun on rank 0 Tue Jan 14 14:41:46 2020


DD  step 100849 load imb.: force  4.7%  pme mesh/force 4.774
step 101000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 127071.6 M-cycles
step 101100: timed with pme grid 60 60 60, coulomb cutoff 1.098: 152794.4 M-cycles
step 101200: timed with pme grid 64 64 64, coulomb cutoff 1.029: 148009.4 M-cycles
step 101300: timed with pme grid 72 72 72, coulomb cutoff 1.000: 325495.4 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 101350 at Tue Jan 14 14:58:09 2020


Writing checkpoint, step 101750 at Tue Jan 14 15:14:27 2020


Writing checkpoint, step 102050 at Tue Jan 14 15:28:36 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   140780
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 2029 2976
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 2029 2976
Minimum cell size due to bonded interactions: 0.502 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 70 min 4292 max 4556

Started mdrun on rank 0 Tue Jan 14 15:43:07 2020


DD  step 102099 load imb.: force  8.7%  pme mesh/force 6.265
step 102250: timed with pme grid 72 72 72, coulomb cutoff 1.000: 63316.7 M-cycles
step 102350: timed with pme grid 60 60 60, coulomb cutoff 1.098: 66667.1 M-cycles
step 102450: timed with pme grid 52 52 52, coulomb cutoff 1.267: 65483.2 M-cycles
step 102550: timed with pme grid 48 48 48, coulomb cutoff 1.373: 64619.3 M-cycles
step 102650: timed with pme grid 44 44 44, coulomb cutoff 1.497: 64889.0 M-cycles
step 102650: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 102750: timed with pme grid 44 44 44, coulomb cutoff 1.497: 57118.4 M-cycles
step 102850: timed with pme grid 48 48 48, coulomb cutoff 1.373: 64404.6 M-cycles
step 102950: timed with pme grid 52 52 52, coulomb cutoff 1.267: 67114.4 M-cycles
step 103050: timed with pme grid 56 56 56, coulomb cutoff 1.177: 63997.3 M-cycles
step 103150: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64666.1 M-cycles
step 103250: timed with pme grid 64 64 64, coulomb cutoff 1.029: 66553.4 M-cycles
Writing checkpoint, step 103250 at Tue Jan 14 15:58:47 2020


step 103350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 62176.8 M-cycles
step 103450: timed with pme grid 44 44 44, coulomb cutoff 1.497: 67711.8 M-cycles
step 103550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 68226.9 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.497
Writing checkpoint, step 104450 at Tue Jan 14 16:13:40 2020


Writing checkpoint, step 105700 at Tue Jan 14 16:28:28 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   178359
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.454 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.454 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 62 min 4304 max 4524

Started mdrun on rank 0 Tue Jan 14 16:47:10 2020


DD  step 105749 load imb.: force  7.1%  pme mesh/force 3.926
step 105900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 145253.1 M-cycles
step 106000: timed with pme grid 60 60 60, coulomb cutoff 1.098: 155372.6 M-cycles
step 106100: timed with pme grid 52 52 52, coulomb cutoff 1.267: 138572.3 M-cycles
step 106200: timed with pme grid 48 48 48, coulomb cutoff 1.372: 120872.6 M-cycles
step 106300: timed with pme grid 44 44 44, coulomb cutoff 1.497: 148007.9 M-cycles
Writing checkpoint, step 106350 at Tue Jan 14 17:03:53 2020


step 106400: timed with pme grid 48 48 48, coulomb cutoff 1.372: 212484.9 M-cycles
              optimal pme grid 48 48 48, coulomb cutoff 1.372
Writing checkpoint, step 106700 at Tue Jan 14 17:18:08 2020


Writing checkpoint, step 107350 at Tue Jan 14 17:33:04 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   76734
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.454 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.454 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.510 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4295 max 4556

Started mdrun on rank 0 Tue Jan 14 17:49:44 2020


DD  step 107399 load imb.: force  7.8%  pme mesh/force 8.087
step 107550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 102876.3 M-cycles
step 107650: timed with pme grid 60 60 60, coulomb cutoff 1.097: 194718.5 M-cycles
step 107750: timed with pme grid 64 64 64, coulomb cutoff 1.028: 145616.6 M-cycles
step 107850: timed with pme grid 72 72 72, coulomb cutoff 1.000: 169277.1 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 107900 at Tue Jan 14 18:06:04 2020


Writing checkpoint, step 108400 at Tue Jan 14 18:21:57 2020


Writing checkpoint, step 109000 at Tue Jan 14 18:35:29 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   377561
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.453 nm, LJ-14, atoms 2034 2971
  multi-body bonded interactions: 0.453 nm, Ryckaert-Bell., atoms 2971 2034
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.510 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 61 min 4311 max 4561

Started mdrun on rank 0 Tue Jan 14 18:54:09 2020


DD  step 109049 load imb.: force  7.3%  pme mesh/force 2.862
step 109200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 252059.2 M-cycles
step 109300: timed with pme grid 60 60 60, coulomb cutoff 1.097: 184823.2 M-cycles
step 109400: timed with pme grid 52 52 52, coulomb cutoff 1.266: 157936.9 M-cycles
step 109500: timed with pme grid 48 48 48, coulomb cutoff 1.371: 195133.0 M-cycles
Writing checkpoint, step 109500 at Tue Jan 14 19:10:00 2020


step 109600: timed with pme grid 52 52 52, coulomb cutoff 1.266: 207236.8 M-cycles
step 109700: timed with pme grid 56 56 56, coulomb cutoff 1.175: 230983.2 M-cycles
              optimal pme grid 52 52 52, coulomb cutoff 1.266
Writing checkpoint, step 109900 at Tue Jan 14 19:26:35 2020


Writing checkpoint, step 110250 at Tue Jan 14 19:39:56 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   36180
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.459 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.459 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.505 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4281 max 4552

Started mdrun on rank 0 Tue Jan 14 19:56:01 2020


DD  step 110299 load imb.: force  9.7%  pme mesh/force 2.909
step 110450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 187635.4 M-cycles
step 110550: timed with pme grid 60 60 60, coulomb cutoff 1.097: 235631.6 M-cycles
step 110650: timed with pme grid 64 64 64, coulomb cutoff 1.028: 169889.4 M-cycles
step 110750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 341501.5 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.028
Writing checkpoint, step 110750 at Tue Jan 14 20:13:19 2020


Writing checkpoint, step 111150 at Tue Jan 14 20:27:39 2020


Writing checkpoint, step 111550 at Tue Jan 14 20:42:36 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   56685
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.458 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.458 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.504 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 68 min 4288 max 4561

Started mdrun on rank 0 Tue Jan 14 21:00:26 2020


DD  step 111599 load imb.: force  5.5%  pme mesh/force 4.016
step 111750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73193.4 M-cycles
step 111850: timed with pme grid 60 60 60, coulomb cutoff 1.097: 70748.2 M-cycles
step 111950: timed with pme grid 52 52 52, coulomb cutoff 1.266: 76322.1 M-cycles
step 112050: timed with pme grid 48 48 48, coulomb cutoff 1.372: 84419.6 M-cycles
step 112150: timed with pme grid 52 52 52, coulomb cutoff 1.266: 75895.1 M-cycles
step 112250: timed with pme grid 56 56 56, coulomb cutoff 1.176: 71511.3 M-cycles
step 112350: timed with pme grid 60 60 60, coulomb cutoff 1.097: 76171.4 M-cycles
step 112450: timed with pme grid 64 64 64, coulomb cutoff 1.029: 75898.7 M-cycles
step 112550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71180.5 M-cycles
step 112650: timed with pme grid 52 52 52, coulomb cutoff 1.266: 75409.1 M-cycles
Writing checkpoint, step 112700 at Tue Jan 14 21:15:53 2020


step 112750: timed with pme grid 56 56 56, coulomb cutoff 1.176: 75528.1 M-cycles
step 112850: timed with pme grid 60 60 60, coulomb cutoff 1.097: 81954.2 M-cycles
step 112950: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71827.5 M-cycles
step 113050: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74169.8 M-cycles
step 113150: timed with pme grid 52 52 52, coulomb cutoff 1.266: 75841.3 M-cycles
step 113250: timed with pme grid 56 56 56, coulomb cutoff 1.176: 73977.0 M-cycles
step 113350: timed with pme grid 60 60 60, coulomb cutoff 1.097: 70822.0 M-cycles
step 113450: timed with pme grid 64 64 64, coulomb cutoff 1.029: 60388.2 M-cycles
step 113550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73804.0 M-cycles
step 113650: timed with pme grid 64 64 64, coulomb cutoff 1.029: 74094.4 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.029
Writing checkpoint, step 113850 at Tue Jan 14 21:30:55 2020


Writing checkpoint, step 115050 at Tue Jan 14 21:45:50 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   170942
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.456 nm, LJ-14, atoms 2029 2976
  multi-body bonded interactions: 0.456 nm, Ryckaert-Bell., atoms 2029 2976
Minimum cell size due to bonded interactions: 0.501 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.512 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 68 min 4275 max 4565

Started mdrun on rank 0 Tue Jan 14 22:03:24 2020


DD  step 115099 load imb.: force  5.3%  pme mesh/force 6.215
step 115250: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71449.3 M-cycles
step 115350: timed with pme grid 60 60 60, coulomb cutoff 1.097: 74296.5 M-cycles
step 115450: timed with pme grid 52 52 52, coulomb cutoff 1.266: 71040.3 M-cycles
step 115550: timed with pme grid 48 48 48, coulomb cutoff 1.372: 71888.7 M-cycles
step 115650: timed with pme grid 44 44 44, coulomb cutoff 1.497: 77941.5 M-cycles
step 115650: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 115750: timed with pme grid 44 44 44, coulomb cutoff 1.497: 72789.3 M-cycles
step 115850: timed with pme grid 48 48 48, coulomb cutoff 1.372: 77511.6 M-cycles
step 115950: timed with pme grid 52 52 52, coulomb cutoff 1.266: 76992.3 M-cycles
step 116050: timed with pme grid 56 56 56, coulomb cutoff 1.176: 76116.1 M-cycles
step 116150: timed with pme grid 60 60 60, coulomb cutoff 1.097: 71316.2 M-cycles
step 116250: timed with pme grid 64 64 64, coulomb cutoff 1.029: 72507.2 M-cycles
Writing checkpoint, step 116250 at Tue Jan 14 22:19:09 2020


step 116350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76145.1 M-cycles
step 116450: timed with pme grid 44 44 44, coulomb cutoff 1.497: 73813.8 M-cycles
step 116550: timed with pme grid 48 48 48, coulomb cutoff 1.372: 76408.6 M-cycles
step 116650: timed with pme grid 52 52 52, coulomb cutoff 1.266: 72880.6 M-cycles
step 116750: timed with pme grid 56 56 56, coulomb cutoff 1.176: 72546.9 M-cycles
step 116850: timed with pme grid 60 60 60, coulomb cutoff 1.097: 73139.1 M-cycles
step 116950: timed with pme grid 64 64 64, coulomb cutoff 1.029: 76078.8 M-cycles
step 117050: timed with pme grid 72 72 72, coulomb cutoff 1.000: 69331.2 M-cycles
step 117150: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74676.8 M-cycles
step 117250: timed with pme grid 48 48 48, coulomb cutoff 1.372: 73677.7 M-cycles
step 117350: timed with pme grid 52 52 52, coulomb cutoff 1.266: 70569.5 M-cycles
Writing checkpoint, step 117400 at Tue Jan 14 22:34:04 2020


step 117450: timed with pme grid 56 56 56, coulomb cutoff 1.176: 78913.2 M-cycles
step 117550: timed with pme grid 60 60 60, coulomb cutoff 1.097: 75677.2 M-cycles
step 117650: timed with pme grid 64 64 64, coulomb cutoff 1.029: 76122.9 M-cycles
step 117750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71445.3 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 118500 at Tue Jan 14 22:48:34 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   260785
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.455 nm, LJ-14, atoms 5359 6187
  multi-body bonded interactions: 0.455 nm, Ryckaert-Bell., atoms 5359 6187
Minimum cell size due to bonded interactions: 0.500 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 59 min 4296 max 4530

Started mdrun on rank 0 Tue Jan 14 23:07:45 2020


DD  step 118549 load imb.: force  6.8%  pme mesh/force 6.741
step 118700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73924.5 M-cycles
step 118800: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64886.2 M-cycles
step 118900: timed with pme grid 52 52 52, coulomb cutoff 1.267: 69420.3 M-cycles
step 119000: timed with pme grid 48 48 48, coulomb cutoff 1.373: 71748.7 M-cycles
step 119100: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74072.9 M-cycles
step 119200: timed with pme grid 48 48 48, coulomb cutoff 1.373: 70710.5 M-cycles
step 119300: timed with pme grid 52 52 52, coulomb cutoff 1.267: 75489.6 M-cycles
step 119400: timed with pme grid 56 56 56, coulomb cutoff 1.177: 78170.9 M-cycles
step 119500: timed with pme grid 60 60 60, coulomb cutoff 1.098: 76903.7 M-cycles
step 119600: timed with pme grid 64 64 64, coulomb cutoff 1.029: 76112.5 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.098
Writing checkpoint, step 119700 at Tue Jan 14 23:23:27 2020


Writing checkpoint, step 120900 at Tue Jan 14 23:38:32 2020


Writing checkpoint, step 122100 at Tue Jan 14 23:53:22 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   420861
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.462 nm, LJ-14, atoms 2034 2971
  multi-body bonded interactions: 0.462 nm, Ryckaert-Bell., atoms 2971 2034
Minimum cell size due to bonded interactions: 0.509 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.512 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4284 max 4604

Started mdrun on rank 0 Wed Jan 15 00:18:09 2020


DD  step 122149 load imb.: force  6.5%  pme mesh/force 3.644
step 122300: timed with pme grid 72 72 72, coulomb cutoff 1.000: 79545.9 M-cycles
step 122400: timed with pme grid 60 60 60, coulomb cutoff 1.097: 90795.7 M-cycles
step 122500: timed with pme grid 64 64 64, coulomb cutoff 1.029: 96565.3 M-cycles
step 122600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 82150.6 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 123050 at Wed Jan 15 00:33:26 2020


Writing checkpoint, step 124000 at Wed Jan 15 00:48:52 2020


Writing checkpoint, step 124900 at Wed Jan 15 01:03:24 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   75495
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.459 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.459 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.505 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 65 min 4302 max 4564

Started mdrun on rank 0 Wed Jan 15 01:21:47 2020


DD  step 124949 load imb.: force  5.5%  pme mesh/force 4.674
step 125100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 93295.6 M-cycles
step 125200: timed with pme grid 60 60 60, coulomb cutoff 1.097: 90033.6 M-cycles
step 125300: timed with pme grid 52 52 52, coulomb cutoff 1.266: 88080.7 M-cycles
step 125400: timed with pme grid 48 48 48, coulomb cutoff 1.371: 74165.0 M-cycles
step 125500: timed with pme grid 44 44 44, coulomb cutoff 1.496: 74402.3 M-cycles
step 125500: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 125600: timed with pme grid 44 44 44, coulomb cutoff 1.496: 67097.9 M-cycles
step 125700: timed with pme grid 48 48 48, coulomb cutoff 1.371: 68460.4 M-cycles
step 125800: timed with pme grid 44 44 44, coulomb cutoff 1.496: 68977.6 M-cycles
step 125900: timed with pme grid 48 48 48, coulomb cutoff 1.371: 141049.5 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.496
Writing checkpoint, step 125900 at Wed Jan 15 01:37:12 2020


Writing checkpoint, step 127050 at Wed Jan 15 01:52:33 2020


Writing checkpoint, step 128150 at Wed Jan 15 02:07:09 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   175542
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.455 nm, LJ-14, atoms 321 1323
  multi-body bonded interactions: 0.455 nm, Ryckaert-Bell., atoms 321 1323
Minimum cell size due to bonded interactions: 0.501 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4288 max 4552

Started mdrun on rank 0 Wed Jan 15 02:24:00 2020


DD  step 128199 load imb.: force 14.5%  pme mesh/force 6.453
step 128350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76300.4 M-cycles
step 128450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73716.9 M-cycles
step 128550: timed with pme grid 52 52 52, coulomb cutoff 1.267: 70169.5 M-cycles
step 128650: timed with pme grid 48 48 48, coulomb cutoff 1.373: 74271.5 M-cycles
step 128750: timed with pme grid 44 44 44, coulomb cutoff 1.498: 75385.7 M-cycles
step 128750: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.498
step 128850: timed with pme grid 44 44 44, coulomb cutoff 1.498: 61077.2 M-cycles
step 128950: timed with pme grid 48 48 48, coulomb cutoff 1.373: 67914.7 M-cycles
step 129050: timed with pme grid 52 52 52, coulomb cutoff 1.267: 68043.6 M-cycles
step 129150: timed with pme grid 56 56 56, coulomb cutoff 1.177: 77674.6 M-cycles
step 129250: timed with pme grid 60 60 60, coulomb cutoff 1.098: 76021.6 M-cycles
step 129350: timed with pme grid 64 64 64, coulomb cutoff 1.030: 72296.3 M-cycles
Writing checkpoint, step 129350 at Wed Jan 15 02:39:25 2020


step 129450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73152.9 M-cycles
step 129550: timed with pme grid 44 44 44, coulomb cutoff 1.498: 74767.5 M-cycles
step 129650: timed with pme grid 48 48 48, coulomb cutoff 1.373: 77013.2 M-cycles
step 129750: timed with pme grid 52 52 52, coulomb cutoff 1.267: 66991.9 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.498
Writing checkpoint, step 130500 at Wed Jan 15 02:54:33 2020


Writing checkpoint, step 131600 at Wed Jan 15 03:09:14 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   282982
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.454 nm, LJ-14, atoms 321 1323
  multi-body bonded interactions: 0.454 nm, Ryckaert-Bell., atoms 321 1323
Minimum cell size due to bonded interactions: 0.499 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.52 nm Y 3.52 nm Z 3.52 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.515 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 56 min 4314 max 4518

Started mdrun on rank 0 Wed Jan 15 03:26:47 2020


DD  step 131649 load imb.: force  8.9%  pme mesh/force 6.368
step 131800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74935.0 M-cycles
step 131900: timed with pme grid 60 60 60, coulomb cutoff 1.099: 77937.3 M-cycles
step 132000: timed with pme grid 52 52 52, coulomb cutoff 1.268: 67988.3 M-cycles
step 132100: timed with pme grid 48 48 48, coulomb cutoff 1.373: 67184.0 M-cycles
step 132200: timed with pme grid 44 44 44, coulomb cutoff 1.498: 76038.5 M-cycles
step 132300: timed with pme grid 48 48 48, coulomb cutoff 1.373: 77496.7 M-cycles
step 132400: timed with pme grid 52 52 52, coulomb cutoff 1.268: 70758.5 M-cycles
step 132500: timed with pme grid 56 56 56, coulomb cutoff 1.177: 71707.0 M-cycles
step 132600: timed with pme grid 64 64 64, coulomb cutoff 1.030: 75553.4 M-cycles
step 132700: timed with pme grid 72 72 72, coulomb cutoff 1.000: 75769.7 M-cycles
              optimal pme grid 48 48 48, coulomb cutoff 1.373
Writing checkpoint, step 132800 at Wed Jan 15 03:42:17 2020


Writing checkpoint, step 134000 at Wed Jan 15 03:57:22 2020


Writing checkpoint, step 135200 at Wed Jan 15 04:12:15 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   364573
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.453 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.453 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.498 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 69 min 4280 max 4560

Started mdrun on rank 0 Wed Jan 15 04:28:57 2020


DD  step 135249 load imb.: force 12.7%  pme mesh/force 6.271
step 135400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71702.9 M-cycles
step 135500: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73749.8 M-cycles
step 135600: timed with pme grid 52 52 52, coulomb cutoff 1.267: 79819.7 M-cycles
step 135700: timed with pme grid 48 48 48, coulomb cutoff 1.373: 76814.8 M-cycles
step 135800: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74570.2 M-cycles
step 135800: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 135900: timed with pme grid 44 44 44, coulomb cutoff 1.497: 68724.3 M-cycles
step 136000: timed with pme grid 48 48 48, coulomb cutoff 1.373: 76053.1 M-cycles
step 136100: timed with pme grid 52 52 52, coulomb cutoff 1.267: 71978.1 M-cycles
step 136200: timed with pme grid 56 56 56, coulomb cutoff 1.177: 71200.0 M-cycles
step 136300: timed with pme grid 60 60 60, coulomb cutoff 1.098: 72227.0 M-cycles
step 136400: timed with pme grid 64 64 64, coulomb cutoff 1.030: 76673.9 M-cycles
Writing checkpoint, step 136400 at Wed Jan 15 04:44:33 2020


step 136500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71531.0 M-cycles
step 136600: timed with pme grid 44 44 44, coulomb cutoff 1.497: 76067.2 M-cycles
step 136700: timed with pme grid 48 48 48, coulomb cutoff 1.373: 69938.9 M-cycles
step 136800: timed with pme grid 52 52 52, coulomb cutoff 1.267: 66772.5 M-cycles
step 136900: timed with pme grid 56 56 56, coulomb cutoff 1.177: 74505.6 M-cycles
step 137000: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73214.2 M-cycles
step 137100: timed with pme grid 64 64 64, coulomb cutoff 1.030: 72215.8 M-cycles
step 137200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 75474.1 M-cycles
step 137300: timed with pme grid 44 44 44, coulomb cutoff 1.497: 71601.1 M-cycles
step 137400: timed with pme grid 48 48 48, coulomb cutoff 1.373: 73709.5 M-cycles
step 137500: timed with pme grid 52 52 52, coulomb cutoff 1.267: 75692.4 M-cycles
Writing checkpoint, step 137550 at Wed Jan 15 04:59:21 2020


step 137600: timed with pme grid 56 56 56, coulomb cutoff 1.177: 74357.8 M-cycles
step 137700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 71400.7 M-cycles
step 137800: timed with pme grid 64 64 64, coulomb cutoff 1.030: 76143.7 M-cycles
step 137900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72214.8 M-cycles
              optimal pme grid 52 52 52, coulomb cutoff 1.267
Writing checkpoint, step 138800 at Wed Jan 15 05:14:09 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   217095
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.459 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.459 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.505 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 66 min 4281 max 4581

Started mdrun on rank 0 Wed Jan 15 05:32:06 2020


DD  step 138849 load imb.: force 10.6%  pme mesh/force 5.623
step 139000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73853.0 M-cycles
step 139100: timed with pme grid 60 60 60, coulomb cutoff 1.098: 72649.4 M-cycles
step 139200: timed with pme grid 52 52 52, coulomb cutoff 1.267: 76215.9 M-cycles
step 139300: timed with pme grid 48 48 48, coulomb cutoff 1.372: 74050.5 M-cycles
step 139400: timed with pme grid 44 44 44, coulomb cutoff 1.497: 76742.8 M-cycles
step 139400: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 139500: timed with pme grid 44 44 44, coulomb cutoff 1.497: 68015.6 M-cycles
step 139600: timed with pme grid 48 48 48, coulomb cutoff 1.372: 68566.5 M-cycles
step 139700: timed with pme grid 52 52 52, coulomb cutoff 1.267: 75310.2 M-cycles
step 139800: timed with pme grid 56 56 56, coulomb cutoff 1.176: 71152.4 M-cycles
step 139900: timed with pme grid 60 60 60, coulomb cutoff 1.098: 75143.9 M-cycles
step 140000: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71761.8 M-cycles
Writing checkpoint, step 140000 at Wed Jan 15 05:47:41 2020


step 140100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73584.3 M-cycles
step 140200: timed with pme grid 44 44 44, coulomb cutoff 1.497: 71404.3 M-cycles
step 140300: timed with pme grid 48 48 48, coulomb cutoff 1.372: 77509.6 M-cycles
step 140400: timed with pme grid 52 52 52, coulomb cutoff 1.267: 74782.8 M-cycles
step 140500: timed with pme grid 56 56 56, coulomb cutoff 1.176: 73401.3 M-cycles
step 140600: timed with pme grid 60 60 60, coulomb cutoff 1.098: 75408.6 M-cycles
step 140700: timed with pme grid 64 64 64, coulomb cutoff 1.029: 76393.9 M-cycles
step 140800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 69317.9 M-cycles
step 140900: timed with pme grid 44 44 44, coulomb cutoff 1.497: 79390.2 M-cycles
step 141000: timed with pme grid 48 48 48, coulomb cutoff 1.372: 78963.4 M-cycles
step 141100: timed with pme grid 52 52 52, coulomb cutoff 1.267: 75105.7 M-cycles
Writing checkpoint, step 141100 at Wed Jan 15 06:02:18 2020


step 141200: timed with pme grid 56 56 56, coulomb cutoff 1.176: 81107.0 M-cycles
step 141300: timed with pme grid 60 60 60, coulomb cutoff 1.098: 78370.5 M-cycles
step 141400: timed with pme grid 64 64 64, coulomb cutoff 1.029: 65069.2 M-cycles
step 141500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 75164.6 M-cycles
step 141600: timed with pme grid 44 44 44, coulomb cutoff 1.497: 73615.5 M-cycles
step 141700: timed with pme grid 48 48 48, coulomb cutoff 1.372: 74607.4 M-cycles
step 141800: timed with pme grid 56 56 56, coulomb cutoff 1.176: 74413.7 M-cycles
step 141900: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73965.1 M-cycles
step 142000: timed with pme grid 64 64 64, coulomb cutoff 1.029: 79853.3 M-cycles
step 142100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73136.1 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.029
Writing checkpoint, step 142250 at Wed Jan 15 06:17:36 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   71327
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.460 nm, LJ-14, atoms 3581 4708
  multi-body bonded interactions: 0.460 nm, Ryckaert-Bell., atoms 4708 3581
Minimum cell size due to bonded interactions: 0.507 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.52 nm Y 3.52 nm Z 3.52 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.516 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 70 min 4268 max 4558

Started mdrun on rank 0 Wed Jan 15 06:35:22 2020


DD  step 142299 load imb.: force  8.6%  pme mesh/force 4.842
step 142450: timed with pme grid 72 72 72, coulomb cutoff 1.000: 77557.0 M-cycles
step 142550: timed with pme grid 60 60 60, coulomb cutoff 1.099: 110000.9 M-cycles
step 142650: timed with pme grid 64 64 64, coulomb cutoff 1.030: 72434.2 M-cycles
step 142750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 90695.8 M-cycles
              optimal pme grid 64 64 64, coulomb cutoff 1.030
Writing checkpoint, step 143250 at Wed Jan 15 06:50:59 2020


Writing checkpoint, step 144100 at Wed Jan 15 07:06:07 2020


Writing checkpoint, step 145050 at Wed Jan 15 07:21:17 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   158669
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.502 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 71 min 4272 max 4564

Started mdrun on rank 0 Wed Jan 15 07:40:27 2020


DD  step 145099 load imb.: force  6.8%  pme mesh/force 5.731
step 145250: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73305.9 M-cycles
step 145350: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73431.4 M-cycles
step 145450: timed with pme grid 52 52 52, coulomb cutoff 1.267: 72461.0 M-cycles
step 145550: timed with pme grid 48 48 48, coulomb cutoff 1.372: 72839.3 M-cycles
step 145650: timed with pme grid 44 44 44, coulomb cutoff 1.497: 72950.1 M-cycles
step 145650: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 145750: timed with pme grid 44 44 44, coulomb cutoff 1.497: 71272.1 M-cycles
step 145850: timed with pme grid 48 48 48, coulomb cutoff 1.372: 69833.2 M-cycles
step 145950: timed with pme grid 52 52 52, coulomb cutoff 1.267: 74954.7 M-cycles
step 146050: timed with pme grid 56 56 56, coulomb cutoff 1.176: 76322.8 M-cycles
step 146150: timed with pme grid 60 60 60, coulomb cutoff 1.098: 72654.5 M-cycles
step 146250: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71911.8 M-cycles
Writing checkpoint, step 146250 at Wed Jan 15 07:56:08 2020


step 146350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71449.2 M-cycles
step 146450: timed with pme grid 44 44 44, coulomb cutoff 1.497: 74115.9 M-cycles
step 146550: timed with pme grid 48 48 48, coulomb cutoff 1.372: 73675.0 M-cycles
step 146650: timed with pme grid 52 52 52, coulomb cutoff 1.267: 75277.9 M-cycles
step 146750: timed with pme grid 56 56 56, coulomb cutoff 1.176: 71479.5 M-cycles
step 146850: timed with pme grid 60 60 60, coulomb cutoff 1.098: 73627.3 M-cycles
step 146950: timed with pme grid 64 64 64, coulomb cutoff 1.029: 70965.2 M-cycles
step 147050: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73645.5 M-cycles
step 147150: timed with pme grid 44 44 44, coulomb cutoff 1.497: 76697.9 M-cycles
step 147250: timed with pme grid 48 48 48, coulomb cutoff 1.372: 70855.5 M-cycles
step 147350: timed with pme grid 52 52 52, coulomb cutoff 1.267: 73080.6 M-cycles
Writing checkpoint, step 147400 at Wed Jan 15 08:10:56 2020


step 147450: timed with pme grid 56 56 56, coulomb cutoff 1.176: 71370.0 M-cycles
step 147550: timed with pme grid 60 60 60, coulomb cutoff 1.098: 72748.0 M-cycles
step 147650: timed with pme grid 64 64 64, coulomb cutoff 1.029: 74888.4 M-cycles
step 147750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 72955.1 M-cycles
              optimal pme grid 48 48 48, coulomb cutoff 1.372
Writing checkpoint, step 148550 at Wed Jan 15 08:25:44 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   392522
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.459 nm, LJ-14, atoms 321 1323
  multi-body bonded interactions: 0.459 nm, Ryckaert-Bell., atoms 321 1323
Minimum cell size due to bonded interactions: 0.505 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 64 min 4263 max 4527

Started mdrun on rank 0 Wed Jan 15 08:42:59 2020


DD  step 148599 load imb.: force 16.6%  pme mesh/force 6.367
step 148750: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70032.8 M-cycles
step 148850: timed with pme grid 60 60 60, coulomb cutoff 1.098: 67896.9 M-cycles
step 148950: timed with pme grid 52 52 52, coulomb cutoff 1.267: 76177.4 M-cycles
step 149050: timed with pme grid 56 56 56, coulomb cutoff 1.176: 71942.5 M-cycles
step 149150: timed with pme grid 60 60 60, coulomb cutoff 1.098: 81468.5 M-cycles
step 149250: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71031.5 M-cycles
step 149350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 71252.9 M-cycles
              optimal pme grid 60 60 60, coulomb cutoff 1.098
Writing checkpoint, step 149750 at Wed Jan 15 08:58:22 2020



DD  step 149999 load imb.: force 11.1%  pme mesh/force 4.556
           Step           Time
         150000      300.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Ryckaert-Bell.          LJ-14     Coulomb-14
    1.36618e+04    8.04870e+02    5.86140e+03    9.62045e+03    5.17771e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    3.27764e+05   -1.58501e+04   -2.24108e+06    7.46450e+03   -1.83998e+06
    Kinetic En.   Total Energy  Conserved En.    Temperature Pres. DC (bar)
    2.93863e+05   -1.54612e+06   -1.55332e+06    2.99856e+02   -2.25334e+02
 Pressure (bar)   Constr. rmsd
    4.19054e+00    2.77456e-05

Writing checkpoint, step 151050 at Wed Jan 15 09:13:35 2020


Writing checkpoint, step 152200 at Wed Jan 15 09:28:15 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   265549
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.456 nm, LJ-14, atoms 3576 4713
  multi-body bonded interactions: 0.456 nm, Ryckaert-Bell., atoms 3576 4713
Minimum cell size due to bonded interactions: 0.501 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 61 min 4292 max 4494

Started mdrun on rank 0 Wed Jan 15 09:46:31 2020


DD  step 152249 load imb.: force  7.1%  pme mesh/force 6.893
step 152400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74978.7 M-cycles
step 152500: timed with pme grid 60 60 60, coulomb cutoff 1.097: 69927.3 M-cycles
step 152600: timed with pme grid 52 52 52, coulomb cutoff 1.266: 78134.5 M-cycles
step 152700: timed with pme grid 48 48 48, coulomb cutoff 1.372: 76106.1 M-cycles
step 152800: timed with pme grid 44 44 44, coulomb cutoff 1.496: 69029.6 M-cycles
step 152800: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 152900: timed with pme grid 44 44 44, coulomb cutoff 1.496: 76539.5 M-cycles
step 153000: timed with pme grid 48 48 48, coulomb cutoff 1.372: 68977.3 M-cycles
step 153100: timed with pme grid 52 52 52, coulomb cutoff 1.266: 66859.5 M-cycles
step 153200: timed with pme grid 56 56 56, coulomb cutoff 1.176: 72578.7 M-cycles
step 153300: timed with pme grid 60 60 60, coulomb cutoff 1.097: 74421.8 M-cycles
step 153400: timed with pme grid 64 64 64, coulomb cutoff 1.029: 70884.2 M-cycles
Writing checkpoint, step 153400 at Wed Jan 15 10:02:08 2020


step 153500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 74703.9 M-cycles
step 153600: timed with pme grid 44 44 44, coulomb cutoff 1.496: 74154.4 M-cycles
step 153700: timed with pme grid 48 48 48, coulomb cutoff 1.372: 69891.7 M-cycles
step 153800: timed with pme grid 52 52 52, coulomb cutoff 1.266: 68229.8 M-cycles
step 153900: timed with pme grid 56 56 56, coulomb cutoff 1.176: 69803.8 M-cycles
step 154000: timed with pme grid 60 60 60, coulomb cutoff 1.097: 75189.3 M-cycles
step 154100: timed with pme grid 64 64 64, coulomb cutoff 1.029: 73652.8 M-cycles
step 154200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 69443.2 M-cycles
step 154300: timed with pme grid 44 44 44, coulomb cutoff 1.496: 73334.3 M-cycles
step 154400: timed with pme grid 48 48 48, coulomb cutoff 1.372: 73812.3 M-cycles
step 154500: timed with pme grid 52 52 52, coulomb cutoff 1.266: 72729.3 M-cycles
Writing checkpoint, step 154550 at Wed Jan 15 10:16:58 2020


step 154600: timed with pme grid 56 56 56, coulomb cutoff 1.176: 69448.4 M-cycles
step 154700: timed with pme grid 60 60 60, coulomb cutoff 1.097: 72718.1 M-cycles
step 154800: timed with pme grid 64 64 64, coulomb cutoff 1.029: 78587.5 M-cycles
step 154900: timed with pme grid 72 72 72, coulomb cutoff 1.000: 73529.1 M-cycles
              optimal pme grid 52 52 52, coulomb cutoff 1.266
Writing checkpoint, step 155750 at Wed Jan 15 10:32:09 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   1260
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.458 nm, LJ-14, atoms 5359 6187
  multi-body bonded interactions: 0.458 nm, Ryckaert-Bell., atoms 5359 6187
Minimum cell size due to bonded interactions: 0.504 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 68 min 4303 max 4561

Started mdrun on rank 0 Wed Jan 15 10:52:54 2020


DD  step 155799 load imb.: force  6.5%  pme mesh/force 4.820
step 155950: timed with pme grid 72 72 72, coulomb cutoff 1.000: 78037.0 M-cycles
step 156050: timed with pme grid 60 60 60, coulomb cutoff 1.098: 84540.5 M-cycles
step 156150: timed with pme grid 52 52 52, coulomb cutoff 1.267: 80106.0 M-cycles
step 156250: timed with pme grid 48 48 48, coulomb cutoff 1.372: 81570.7 M-cycles
step 156350: timed with pme grid 44 44 44, coulomb cutoff 1.497: 72945.6 M-cycles
step 156350: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 156450: timed with pme grid 44 44 44, coulomb cutoff 1.497: 75797.8 M-cycles
step 156550: timed with pme grid 48 48 48, coulomb cutoff 1.372: 87270.4 M-cycles
step 156650: timed with pme grid 52 52 52, coulomb cutoff 1.267: 114163.0 M-cycles
step 156750: timed with pme grid 56 56 56, coulomb cutoff 1.176: 89218.4 M-cycles
Writing checkpoint, step 156800 at Wed Jan 15 11:08:46 2020


step 156850: timed with pme grid 64 64 64, coulomb cutoff 1.029: 83406.3 M-cycles
step 156950: timed with pme grid 72 72 72, coulomb cutoff 1.000: 75693.2 M-cycles
step 157050: timed with pme grid 44 44 44, coulomb cutoff 1.497: 96555.4 M-cycles
step 157150: timed with pme grid 48 48 48, coulomb cutoff 1.372: 96308.2 M-cycles
step 157250: timed with pme grid 52 52 52, coulomb cutoff 1.267: 80907.6 M-cycles
step 157350: timed with pme grid 72 72 72, coulomb cutoff 1.000: 70566.0 M-cycles
step 157450: timed with pme grid 44 44 44, coulomb cutoff 1.497: 106083.1 M-cycles
step 157550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 97947.5 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 157750 at Wed Jan 15 11:23:26 2020


Writing checkpoint, step 158800 at Wed Jan 15 11:38:06 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   61850
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.502 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.511 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 65 min 4300 max 4544

Started mdrun on rank 0 Wed Jan 15 12:09:38 2020


DD  step 158849 load imb.: force  7.9%  pme mesh/force 6.918
step 159000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 77452.2 M-cycles
step 159100: timed with pme grid 60 60 60, coulomb cutoff 1.097: 70077.0 M-cycles
step 159200: timed with pme grid 52 52 52, coulomb cutoff 1.266: 70347.9 M-cycles
step 159300: timed with pme grid 48 48 48, coulomb cutoff 1.371: 72294.1 M-cycles
step 159400: timed with pme grid 44 44 44, coulomb cutoff 1.496: 75770.9 M-cycles
step 159400: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.496
step 159500: timed with pme grid 44 44 44, coulomb cutoff 1.496: 74149.8 M-cycles
step 159600: timed with pme grid 48 48 48, coulomb cutoff 1.371: 74197.8 M-cycles
step 159700: timed with pme grid 52 52 52, coulomb cutoff 1.266: 73221.5 M-cycles
step 159800: timed with pme grid 56 56 56, coulomb cutoff 1.175: 71648.5 M-cycles
step 159900: timed with pme grid 60 60 60, coulomb cutoff 1.097: 71033.8 M-cycles
step 160000: timed with pme grid 64 64 64, coulomb cutoff 1.029: 73461.7 M-cycles
Writing checkpoint, step 160000 at Wed Jan 15 12:25:06 2020


step 160100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 64243.0 M-cycles
step 160200: timed with pme grid 52 52 52, coulomb cutoff 1.266: 75595.9 M-cycles
step 160300: timed with pme grid 56 56 56, coulomb cutoff 1.175: 77578.6 M-cycles
step 160400: timed with pme grid 60 60 60, coulomb cutoff 1.097: 69274.6 M-cycles
step 160500: timed with pme grid 72 72 72, coulomb cutoff 1.000: 76561.8 M-cycles
              optimal pme grid 72 72 72, coulomb cutoff 1.000
Writing checkpoint, step 161200 at Wed Jan 15 12:40:16 2020


Writing checkpoint, step 162400 at Wed Jan 15 12:55:11 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   205251
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.457 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.457 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.502 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 76 min 4222 max 4584

Started mdrun on rank 0 Wed Jan 15 13:45:45 2020


DD  step 162449 load imb.: force 11.4%  pme mesh/force 6.785
step 162600: timed with pme grid 72 72 72, coulomb cutoff 1.000: 64552.4 M-cycles
step 162700: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64801.5 M-cycles
step 162800: timed with pme grid 52 52 52, coulomb cutoff 1.267: 62412.7 M-cycles
step 162900: timed with pme grid 48 48 48, coulomb cutoff 1.373: 70886.2 M-cycles
step 163000: timed with pme grid 52 52 52, coulomb cutoff 1.267: 68514.2 M-cycles
step 163100: timed with pme grid 56 56 56, coulomb cutoff 1.176: 66643.2 M-cycles
step 163200: timed with pme grid 60 60 60, coulomb cutoff 1.098: 66114.9 M-cycles
step 163300: timed with pme grid 64 64 64, coulomb cutoff 1.029: 66885.9 M-cycles
step 163400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 65009.2 M-cycles
              optimal pme grid 52 52 52, coulomb cutoff 1.267
Writing checkpoint, step 163550 at Wed Jan 15 14:01:02 2020


Writing checkpoint, step 164750 at Wed Jan 15 14:16:12 2020


Writing checkpoint, step 165900 at Wed Jan 15 14:31:03 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   294740
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.460 nm, LJ-14, atoms 326 1318
  multi-body bonded interactions: 0.460 nm, Ryckaert-Bell., atoms 1318 326
Minimum cell size due to bonded interactions: 0.506 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.513 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 73 min 4283 max 4593

Started mdrun on rank 0 Wed Jan 15 14:51:16 2020


DD  step 165949 load imb.: force 11.6%  pme mesh/force 5.849
step 166100: timed with pme grid 72 72 72, coulomb cutoff 1.000: 63861.7 M-cycles
step 166200: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64344.4 M-cycles
step 166300: timed with pme grid 52 52 52, coulomb cutoff 1.267: 65887.3 M-cycles
step 166400: timed with pme grid 48 48 48, coulomb cutoff 1.372: 67665.2 M-cycles
step 166500: timed with pme grid 44 44 44, coulomb cutoff 1.497: 66718.4 M-cycles
step 166500: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 166600: timed with pme grid 44 44 44, coulomb cutoff 1.497: 59981.2 M-cycles
step 166700: timed with pme grid 48 48 48, coulomb cutoff 1.372: 70378.7 M-cycles
step 166800: timed with pme grid 52 52 52, coulomb cutoff 1.267: 66887.3 M-cycles
step 166900: timed with pme grid 56 56 56, coulomb cutoff 1.176: 65974.9 M-cycles
step 167000: timed with pme grid 60 60 60, coulomb cutoff 1.098: 66978.6 M-cycles
step 167100: timed with pme grid 64 64 64, coulomb cutoff 1.029: 66766.2 M-cycles
Writing checkpoint, step 167100 at Wed Jan 15 15:07:03 2020


step 167200: timed with pme grid 72 72 72, coulomb cutoff 1.000: 64269.3 M-cycles
step 167300: timed with pme grid 44 44 44, coulomb cutoff 1.497: 60226.8 M-cycles
step 167400: timed with pme grid 52 52 52, coulomb cutoff 1.267: 63525.8 M-cycles
step 167500: timed with pme grid 56 56 56, coulomb cutoff 1.176: 65590.4 M-cycles
step 167600: timed with pme grid 60 60 60, coulomb cutoff 1.098: 67131.3 M-cycles
step 167700: timed with pme grid 64 64 64, coulomb cutoff 1.029: 67897.7 M-cycles
step 167800: timed with pme grid 72 72 72, coulomb cutoff 1.000: 66476.2 M-cycles
step 167900: timed with pme grid 44 44 44, coulomb cutoff 1.497: 66381.5 M-cycles
step 168000: timed with pme grid 52 52 52, coulomb cutoff 1.267: 60670.5 M-cycles
step 168100: timed with pme grid 56 56 56, coulomb cutoff 1.176: 67997.4 M-cycles
step 168200: timed with pme grid 60 60 60, coulomb cutoff 1.098: 63851.7 M-cycles
Writing checkpoint, step 168250 at Wed Jan 15 15:22:03 2020


step 168300: timed with pme grid 64 64 64, coulomb cutoff 1.029: 71863.6 M-cycles
step 168400: timed with pme grid 72 72 72, coulomb cutoff 1.000: 67788.9 M-cycles
step 168500: timed with pme grid 44 44 44, coulomb cutoff 1.497: 65020.4 M-cycles
step 168600: timed with pme grid 52 52 52, coulomb cutoff 1.267: 65963.2 M-cycles
step 168700: timed with pme grid 56 56 56, coulomb cutoff 1.176: 68362.9 M-cycles
step 168800: timed with pme grid 60 60 60, coulomb cutoff 1.098: 66254.6 M-cycles
step 168900: timed with pme grid 64 64 64, coulomb cutoff 1.029: 67205.9 M-cycles
step 169000: timed with pme grid 72 72 72, coulomb cutoff 1.000: 67673.2 M-cycles
              optimal pme grid 44 44 44, coulomb cutoff 1.497
Writing checkpoint, step 169350 at Wed Jan 15 15:36:27 2020




-----------------------------------------------------------
Restarting from checkpoint, appending to previous log file.

                      :-) GROMACS - gmx mdrun, 2019.3 (-:

Executable:   /shared/ucl/apps/gromacs/2019.3/intel-2018/bin/gmx
Data prefix:  /shared/ucl/apps/gromacs/2019.3/intel-2018
Working dir:  /lustre/scratch/scratch/ucbechz/20200109_Nuria_pH_MD/pH3.5_300K/repeat1
Process ID:   384327
Command line:
  gmx mdrun -deffnm md_0_1 -cpi -append

GROMACS version:    2019.3
Precision:          single
Memory model:       64 bit
MPI library:        thread_mpi
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 64)
GPU support:        disabled
SIMD instructions:  AVX_512
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      disabled
Tracing support:    disabled
C compiler:         /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icc Intel 18.0.3.20180410
C compiler flags:    -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=gnu99  -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  
C++ compiler:       /shared/ucl/apps/intel/2018.Update3/compilers_and_libraries_2018.3.222/linux/bin/intel64/icpc Intel 18.0.3.20180410
C++ compiler flags:  -xCORE-AVX512 -qopt-zmm-usage=high   -mkl=sequential  -std=c++11   -O3 -DNDEBUG -ip -funroll-all-loops -alias-const -ansi-alias -no-prec-div -fimf-domain-exclusion=14 -qoverride-limits  

Changing nstlist from 10 to 50, rlist from 1 to 1.116


Initializing Domain Decomposition on 36 ranks
Dynamic load balancing: locked
Minimum cell size due to atom displacement: 0.479 nm
Initial maximum distances in bonded interactions:
    two-body bonded interactions: 0.462 nm, LJ-14, atoms 5364 6182
  multi-body bonded interactions: 0.462 nm, Ryckaert-Bell., atoms 6182 5364
Minimum cell size due to bonded interactions: 0.509 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.872 nm
Estimated maximum distance required for P-LINCS: 0.872 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 27 particle-particle and 9 PME only ranks
This is a guess, check the performance at the end of the log file
Using 9 separate PME ranks, as guessed by mdrun
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 27 cells with a minimum initial size of 1.089 nm
The maximum allowed number of cells is: X 9 Y 9 Z 9
Domain decomposition grid 3 x 3 x 3, separate PME ranks 9
PME domain decomposition: 3 x 3 x 1
Interleaving PP and PME ranks
This rank does only particle-particle work.
Domain decomposition rank 0, coordinates 0 0 0

The initial number of communication pulses is: X 1 Y 1 Z 1
The initial domain decomposition cell size is: X 3.51 nm Y 3.51 nm Z 3.51 nm

The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
(the following are initial values, they could change due to box deformation)
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  3.514 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 1 Y 1 Z 1
The minimum size for domain decomposition cells is 1.116 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.32 Y 0.32 Z 0.32
The maximum allowed distance for atoms involved in interactions is:
                 non-bonded interactions           1.116 nm
            two-body bonded interactions  (-rdd)   1.116 nm
          multi-body bonded interactions  (-rdd)   1.116 nm
  atoms separated by up to 5 constraints  (-rcon)  1.116 nm

Using 36 MPI threads
Using 1 OpenMP thread per tMPI thread

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073

Long Range LJ corr.: <C6> 3.1893e-04
Generated table with 1058 data points for Ewald.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for LJ12.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1058 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Using SIMD 4x8 nonbonded short-range kernels

Using a dual 4x8 pair-list setup updated with dynamic pruning:
  outer list: updated every 50 steps, buffer 0.116 nm, rlist 1.116 nm
  inner list: updated every 12 steps, buffer 0.003 nm, rlist 1.003 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 50 steps, buffer 0.245 nm, rlist 1.245 nm
  inner list: updated every 12 steps, buffer 0.048 nm, rlist 1.048 nm

Using geometric Lennard-Jones combination rule


Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 6705
There are constraints between atoms in different decomposition domains,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms


Intra-simulation communication will occur every 10 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest
There are: 117860 Atoms
Atom distribution over 27 domains: av 4365 stddev 71 min 4298 max 4582

Started mdrun on rank 0 Wed Jan 15 15:56:38 2020


DD  step 169399 load imb.: force  6.1%  pme mesh/force 6.494
step 169550: timed with pme grid 72 72 72, coulomb cutoff 1.000: 82469.6 M-cycles
step 169650: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64773.1 M-cycles
step 169750: timed with pme grid 52 52 52, coulomb cutoff 1.267: 64189.3 M-cycles
step 169850: timed with pme grid 48 48 48, coulomb cutoff 1.373: 64938.9 M-cycles
step 169950: timed with pme grid 44 44 44, coulomb cutoff 1.497: 64347.6 M-cycles
step 169950: the maximum allowed grid scaling limits the PME load balancing to a coulomb cut-off of 1.497
step 170050: timed with pme grid 44 44 44, coulomb cutoff 1.497: 65865.2 M-cycles
step 170150: timed with pme grid 48 48 48, coulomb cutoff 1.373: 62735.6 M-cycles
step 170250: timed with pme grid 52 52 52, coulomb cutoff 1.267: 65248.2 M-cycles
step 170350: timed with pme grid 56 56 56, coulomb cutoff 1.177: 65351.9 M-cycles
step 170450: timed with pme grid 60 60 60, coulomb cutoff 1.098: 70593.3 M-cycles
step 170550: timed with pme grid 64 64 64, coulomb cutoff 1.030: 66015.8 M-cycles
Writing checkpoint, step 170550 at Wed Jan 15 16:12:24 2020


step 170650: timed with pme grid 44 44 44, coulomb cutoff 1.497: 67227.3 M-cycles
step 170750: timed with pme grid 48 48 48, coulomb cutoff 1.373: 63991.0 M-cycles
step 170850: timed with pme grid 52 52 52, coulomb cutoff 1.267: 69336.2 M-cycles
step 170950: timed with pme grid 56 56 56, coulomb cutoff 1.177: 69715.3 M-cycles
step 171050: timed with pme grid 60 60 60, coulomb cutoff 1.098: 62898.7 M-cycles
step 171150: timed with pme grid 64 64 64, coulomb cutoff 1.030: 63935.8 M-cycles
step 171250: timed with pme grid 44 44 44, coulomb cutoff 1.497: 65860.0 M-cycles
step 171350: timed with pme grid 48 48 48, coulomb cutoff 1.373: 66283.8 M-cycles
step 171450: timed with pme grid 52 52 52, coulomb cutoff 1.267: 65846.7 M-cycles
step 171550: timed with pme grid 56 56 56, coulomb cutoff 1.177: 70096.8 M-cycles
step 171650: timed with pme grid 60 60 60, coulomb cutoff 1.098: 64461.6 M-cycles
Writing checkpoint, step 171650 at Wed Jan 15 16:26:52 2020


step 171750: timed with pme grid 64 64 64, coulomb cutoff 1.030: 68074.2 M-cycles
              optimal pme grid 48 48 48, coulomb cutoff 1.373
Writing checkpoint, step 172850 at Wed Jan 15 16:42:07 2020


